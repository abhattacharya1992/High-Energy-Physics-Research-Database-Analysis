paper_key,key_type,title,abstract,year,authors,url,source,depth,clean_abstract,Topic_r1,Topic_r2,Topic_r3,Topic_final,arxiv_id,doi,is_ml
,,Universality in the resurgence of generalized Tracy-Widom distributions,"We analyze determinants associated with Bessel kernels and generic symbol functions, which govern a class of observables across all values of the 't Hooft coupling in supersymmetric gauge theories. Previous approaches, based on integro-differential equations, have provided systematic strong-coupling expansions for the logarithms of these determinants, expressed through the moments of the symbol. The resulting asymptotic series, once completed with non-perturbative terms, allowed the leading resurgence relations to be tested. In this Letter we focus directly on the determinants themselves, and we uncover a strikingly simple non-perturbative structure: all trans-series corrections share a universal form, while the moments transform in a direct and intuitive way. This simplicity points to an underlying organizing principle for the non-perturbative dynamics of gauge theory observables.",2025,"['Zoltan Bajnok', 'Bercel Boldis', 'Dennis le Plat']",http://arxiv.org/abs/2509.20302v1,arxiv,,,,,,,2509.20302v1,,False
GPU Implementation of Zippel Method for Feynman Integral Reconstruction,unknown,GPU Implementation of Zippel Method for Feynman Integral Reconstruction,"The Zippel algorithm performs a rational reconstruction of multivariate polynomials and aims specifically at the sparse case. It is applied in different fields of science, lately becoming an important step in Feynman integral reduction in elementary particle physics. In some cases with multiple variables it might become a bottleneck for the whole evaluation so that different optimizations are required. In this paper we describe how we ported the classical Zippel algorithm together with its balanced version for rational functions to graphical processor units and perform its evaluation on several GPUs.",2025,"['Smirnov', 'Alexander V.', 'Rozhnov', 'Boris I.', 'Voevodin', 'Vadim V.']",,inspire_citation,3.0,"The Zippel algorithm performs a rational reconstruction of multivariate polynomials and aims specifically at the sparse case. It is applied in different fields of science, lately becoming an important step in Feynman integral reduction in elementary particle physics. In some cases with multiple variables it might become a bottleneck for the whole evaluation so that different optimizations are required. In this paper we describe how we ported the classical Zippel algorithm together with its balanced version for rational functions to graphical processor units and perform its evaluation on several GPUs.",5.0,1.0,1.0,1.0,,,False
,,Performance of heavy-flavour jet identification in Lorentz-boosted   topologies in proton-proton collisions at $\sqrt{s}$ = 13 TeV,"Measurements in the highly Lorentz-boosted regime provoke increased interest in probing the Higgs boson properties and in searching for particles beyond the standard model at the LHC. In the CMS Collaboration, various boosted-object tagging algorithms, designed to identify hadronic jets originating from a massive particle decaying to $\mathrm{b\overline{b}}$ or $\mathrm{c\overline{c}}$, have been developed and deployed across a range of physics analyses. This paper highlights their performance on simulated events, and summarizes novel calibration techniques using proton-proton collision data collected at $\sqrt{s}$ = 13 TeV during the 2016$-$2018 LHC data-taking period. Three dedicated methods are used for the calibration in multijet events, leveraging either machine learning techniques, the presence of muons within energetic boosted jets, or the reconstruction of hadronically decaying high-energy Z bosons. The calibration results, obtained through a combination of these approaches, are presented and discussed.",2025,['CMS Collaboration'],http://arxiv.org/abs/2510.10228v1,arxiv,,,,,,,2510.10228v1,,True
,,Uncovering Singularities in Feynman Integrals via Machine Learning,"We introduce a machine-learning framework based on symbolic regression to extract the full symbol alphabet of multi-loop Feynman integrals. By targeting the analytic structure rather than reduction, the method is broadly applicable and interpretable across different families of integrals. It successfully reconstructs complete symbol alphabets in nontrivial examples, demonstrating both robustness and generality. Beyond accelerating computations case by case, it uncovers the analytic structure universally. This framework opens new avenues for multi-loop amplitude analysis and provides a versatile tool for exploring scattering amplitudes.",2025,"['Yuanche Liu', 'Yingxuan Xu', 'Yang Zhang']",http://arxiv.org/abs/2510.10099v1,arxiv,,,,,,,2510.10099v1,,True
,,Theoretical filters for shift-symmetric Horndeski gravities,"We investigate the structure of nontrivial maximally symmetric vacua and compact-object solutions in shift-symmetric scalar-tensor theories. Focusing on Horndeski gravity, we derive consistency conditions directly from the field equations to identify the subclasses that admit Minkowski and de Sitter vacua with a nontrivial scalar field. In doing so, we obtain a filtering mechanism that operates independently of observational data. In this context, we introduce the notion of stealth vacua, where the scalar field remains active without altering the vacuum. Following this, we examine the theoretical framework of Horndeski theories that admit homogeneous geometries and we extract the implicit form of the solution pertaining to the entire family of theories. Building upon these frameworks, we construct exact solutions in beyond-Horndeski gravity by applying a linear disformal transformation to the regularized Einstein-Gauss-Bonnet black hole. This procedure yields solitonic spacetimes with scalar hair as well as black holes carrying primary scalar hair, demonstrating how disformal maps can qualitatively modify solution properties. We delineate the parameter space in which the transformation is well-defined and analyze the solutions. Our results provide both a principled criterion for selecting viable Horndeski models and a framework for exploring rich solution spaces in beyond-Horndeski gravity.",2025,"['Athanasios Bakopoulos', 'Christos Charmousis', 'Nikos Chatzifotis', 'Theodoros Nakas']",http://arxiv.org/abs/2510.09547v1,arxiv,,,,,,,2510.09547v1,,False
,,Lie symmetry analysis of the two-Higgs-doublet model field equations,"We apply Lie symmetry analysis of partial differential equations (PDEs) to the Euler-Lagrange equations of the two-Higgs-doublet model (2HDM), to determine its scalar Lie point symmetries. A Lie point symmetry is a structure-preserving transformation of the spacetime variables and the fields of the model, which is also continuous and connected to the identity. Symmetries of PDEs may in general be divided into strict variational symmetries, divergence symmetries and non-variational symmetries, where the first two are collectively referred to as variational symmetries. Variational symmetries are usually preserved under quantization, and variational Lie symmetries yield conservation laws. We demonstrate that there are no scalar Lie point divergence symmetries or non-variational Lie point symmetries in the 2HDM, and re-derive its well-known strict variational Lie point symmetries, thus confirming the consistency of our implementation of Lie's method. Moreover, we prove three general results which may simplify Lie symmetry calculations for a wide class of particle physics models. Lie symmetry analysis of PDEs is a broadly applicable method for determining Lie symmetries. As demonstrated here by example, it can be applied to models with many variables, parameters and reparametrization freedom, while any missing discrete symmetries may be identified through the automorphism groups of the resulting Lie symmetry algebras.",2025,['M. Aa. Solberg'],http://arxiv.org/abs/2510.09542v1,arxiv,,,,,,,2510.09542v1,,False
,,Massive Gauge Theories from Consistency Conditions of Amplitudes,"Based on the general principles of Lorentz symmetry and unitary, we introduce two consistency conditions -- on-shell gauge symmetry and strong massive-massless continuation -- in constructing amplitudes of massive gauge theory with elementary particles. In particular we argue on-shell gauge symmtry can be understood as a consequence of Lorentz symmetry, through mixture of a spin-1 block ands a spin-0 block with degnerate mass spectrum. Based on the two conditions, combined with the little group transformation and consistent factorization, we construct 3-point and 4-point vector boson/scalar amplitudes, then analyze the underlying physical models. Given the particle masses, almost all possible vertices, including those involving Goldstone modes, are uniquely fixed. The only exceptions are triple and quartic scalar self-couplings. In addition, all particle masses must have the same physical origin. If the number of vector bosons smaller than 3, the underlying theories for the amplitudes are either massive gauge theories with spontaneous symmetry breaking (S.S.B) or Stueckelberg theory. The necessary condition for the latter is that the scalars have equal masses. We also discuss different models depending on the number of scalars involved. If the number of vector bosons larger than 3, the underlying theory must be Yang-Mills theory with S.S.B. In both abelian and non-abelian cases, the specific shape of Higgs potential cannot be determined, which explains the fact that scalar self-couuplings are undetermined, and the relations between the masses are generally not linear.",2025,['Junmou Chen'],http://arxiv.org/abs/2510.09003v1,arxiv,,,,,,,2510.09003v1,,False
,,Relativistic Particle on Light-Front,"We study Wigner's classification of massive one particle state in a general moving frame in the front form of Lorentz group, characterized and labeled by a special null vector -- reference vector. The little group transformation turns out to be equivalent to a change of reference vector, which also gives a concrete formula to compute the Wigner D-matrices with a general momentum. The little group transformation and Wigner D-matrices have both continuous zero momentum limit and infinite boost (massless) limit, a property that can be called massive-massless continuation. We then apply those results to massive spin-1 particle and compute the corresponding Wigner D-matrices. The resulting polarization vectors are equivalent to those in spinor-helicity formalism. In the massless limit, it is shown that longitudinal polarization decouples from the spectrum. The $\epsilon^\mu_\pm \rightarrow \epsilon^\mu_\pm +\xi k^\mu$ shift turns out to be remnant of this decoupling, with $\xi$ computable from the Wigner D-matrix. Thus in our construction, massless spin-1 particle can be defined as the infinite boost limit of massive spin-1 particle. Our results also give us a deeper understanding of gauge symmetry: it can be understood as the equivalence between obtaining the massless limit for polarization vectors through different reference vectors.",2025,['Junmou Chen'],http://arxiv.org/abs/2510.08983v1,arxiv,,,,,,,2510.08983v1,,False
,,Burnup Measurement using Bent Crystal Spectrometer for Pebble Bed   Reactors,"Burnup measurement is essential for monitoring and controlling pebble bed reactors (PBRs), where fuel pebbles circulate rapidly through the core. However, conventional gamma spectroscopy using high purity germanium (HPGe) detectors is difficult due to high activity levels in discharge pebbles, leading to excessive dead time and Compton scattering. This study explores the use of bent crystal diffraction (BCD) spectrometers to filter the emitted gamma spectrum and isolate key peaks for improved measurement accuracy and speed. Pebble wise depletion calculations were performed and the resulting spectra were analyzed using ray tracing (SHADOW3) and gamma response modeling (GADRAS). Key isotopes, $^{137m}$Ba/$^{137}$Cs, $^{239}$Pu, $^{144}$Ce, $^{148m}$Pm, and $^{140}$La, were found to strongly correlate with burnup, residence time, core passes, plutonium production, and fluence. Machine learning regression models applied to simulated spectra achieved a coefficient of determination ($R^2$) as high as 0.995 for burnup prediction. Among various BCD configurations, mosaic silicon crystals in the (440) orientation combined with an HPGe detector provided optimal performance for $^{137m}$Ba, while (220) and (440) configurations paired with scintillators were effective for the remaining isotopes.",2025,"['Ian Kolaja', 'Lee Bernstein', 'Ludovic Jantzen', 'Eleanor Tubman', 'Tatiana Siaraferas', 'Massimiliano Fratoni']",http://arxiv.org/abs/2510.08835v1,arxiv,,,,,,,2510.08835v1,,True
,,"TIGER: A Topology-Agnostic, Hierarchical Graph Network for Event   Reconstruction","Event reconstruction at the LHC, the task of assigning observed physics objects to their true origins, is a central challenge for precision measurements and searches. Many existing machine learning approaches address this problem but rely on a single event topology, restricting their applicability to realistic analyses where multiple signal and background processes with different structures are present. To overcome this, we present TIGER, a novel hierarchical graph network that is fundamentally topology-agnostic. By incorporating only the common underlying structure of sequential two-body decays, our model can reconstruct complex events without process-specific assumptions. This flexible architecture supports multi-task learning, enabling simultaneous event reconstruction and classification. TIGER thus provides a powerful and generalizable tool for physics analysis at the LHC.",2025,"['Nathalie Soybelman', 'Francesco A. Di Bello', 'Nilotpal Kakati', 'Eilam Gross']",http://arxiv.org/abs/2510.08162v1,arxiv,,,,,,,2510.08162v1,,True
,,Locality-Sensitive Hashing-Based Efficient Point Transformer for Charged   Particle Reconstruction,"Charged particle track reconstruction is a foundational task in collider experiments and the main computational bottleneck in particle reconstruction. Graph neural networks (GNNs) have shown strong performance for this problem, but costly graph construction, irregular computations, and random memory access patterns substantially limit their throughput. The recently proposed Hashing-based Efficient Point Transformer (HEPT) offers a theoretically guaranteed near-linear complexity for large point cloud processing via locality-sensitive hashing (LSH) in attention computations; however, its evaluations have largely focused on embedding quality, and the object condensation pipeline on which HEPT relies requires a post-hoc clustering step (e.g., DBScan) that can dominate runtime. In this work, we make two contributions. First, we present a unified, fair evaluation of physics tracking performance for HEPT and a representative GNN-based pipeline under the same dataset and metrics. Second, we introduce HEPTv2 by extending HEPT with a lightweight decoder that eliminates the clustering stage and directly predicts track assignments. This modification preserves HEPT's regular, hardware-friendly computations while enabling ultra-fast end-to-end inference. On the TrackML dataset, optimized HEPTv2 achieves approximately 28 ms per event on an A100 while maintaining competitive tracking efficiency. These results position HEPTv2 as a practical, scalable alternative to GNN-based pipelines for fast tracking.",2025,"['Shitij Govil', 'Jack P. Rodgers', 'Yuan-Tang Chou', 'Siqi Miao', 'Amit Saha', 'Advaith Anand', 'Kilian Lieret', 'Gage DeZoort', 'Mia Liu', 'Javier Duarte', 'Pan Li', 'Shih-Chieh Hsu']",http://arxiv.org/abs/2510.07594v1,arxiv,,,,,,,2510.07594v1,,True
,,Neural Triangular Transport Maps: A New Approach Towards Sampling in   Lattice QCD,"Lattice field theories are fundamental testbeds for computational physics; yet, sampling their Boltzmann distributions remains challenging due to multimodality and long-range correlations. While normalizing flows offer a promising alternative, their application to large lattices is often constrained by prohibitive memory requirements and the challenge of maintaining sufficient model expressivity. We propose sparse triangular transport maps that explicitly exploit the conditional independence structure of the lattice graph under periodic boundary conditions using monotone rectified neural networks (MRNN). We introduce a comprehensive framework for triangular transport maps that navigates the fundamental trade-off between \emph{exact sparsity} (respecting marginal conditional independence in the target distribution) and \emph{approximate sparsity} (computational tractability without fill-ins). Restricting each triangular map component to a local past enables site-wise parallel evaluation and linear time complexity in lattice size $N$, while preserving the expressive, invertible structure. Using $\phi^4$ in two dimensions as a controlled setting, we analyze how node labelings (orderings) affect the sparsity and performance of triangular maps. We compare against Hybrid Monte Carlo (HMC) and established flow approaches (RealNVP).",2025,"['Andrey Bryutkin', 'Youssef Marzouk']",http://arxiv.org/abs/2510.13112v1,arxiv,,,,,,,2510.13112v1,,True
,,Classification and Birational Equivalence of Dimer Integrable Systems   for Reflexive Polygons,"Brane tilings are bipartite periodic graphs on the 2-torus and realize a large family of 4d N=1 supersymmetric gauge theories corresponding to toric Calabi-Yau 3-folds. We present a complete classification of dimer integrable systems corresponding to the 30 brane tilings whose toric Calabi-Yau 3-folds are given by the 16 reflexive polygons in 2 dimensions. For each dimer integrable system associated to a reflexive polygon, we present the Casimirs, the single Hamiltonian built from 1-loops, the spectral curve, and the Poisson commutation relations. We also identify all birational equivalences between dimer integrable systems in this classification by presenting the birational transformations that match the Casimirs and the Hamiltonians as well as the spectral curves and Poisson structures between equivalent dimer integrable systems. In total, we identify 16 pairs of birationally equivalent dimer integrable systems which combined with Seiberg duality between the corresponding brane tilings form 5 distinct equivalence classes. Echoing phenomena observed for brane brick models realizing a family of 2d (0,2) supersymmetric gauge theories corresponding to toric Calabi-Yau 4-folds, we illustrate that deformations of brane tilings, including mass deformations, correspond to the birational transformations we discover in this work, and leave invariant the number of generators of the mesonic moduli space as well as the corresponding U(1)R-refined Hilbert series.",2025,"['Minsung Kho', 'Norton Lee', 'Rak-Kyeong Seong']",http://arxiv.org/abs/2510.12290v1,arxiv,,,,,,,2510.12290v1,,False
,,Applying Normalizing Flows for spin correlations reconstruction in   associated top-quark pair and dark matter production,"We apply a unified machine-learning framework based on Normalizing Flows (NFs) for the event-by-event reconstruction of invisible momenta and the subsequent evaluation of spin-sensitive observables in top-quark pair and dark-matter (DM) associated production processes. Building on recent studies in single-top + DM topologies, we extend the research to $t\bar{t}$ + DM final states. Inputs to our networks combine low-level four-momenta and missing transverse energy with high-level kinematic and angular variables. We compare a baseline multilayer perceptron (MLP) regressor, an autoregressive flow, and the conditional $\nu$-Flows model -- trained to learn the full conditional density. In these final states all the models perform well and demonstrate high reconstruction quality in independent regions split by $m_{t\bar{t}}$ for validation purposes. We highlight the potential of this approach to be extended to three- and four-top-quark production.",2025,"['E. Abasov', 'L. Dudko', 'E. Iudin', 'A. Markina', 'P. Volkov', 'G. Vorotnikov', 'M. Perfilov', 'A. Zaborenko']",http://arxiv.org/abs/2510.11644v1,arxiv,,,,,,,2510.11644v1,,False
,,Optimised neural networks for online processing of ATLAS calorimeter   data on FPGAs,"A study of neural network architectures for the reconstruction of the energy deposited in the cells of the ATLAS liquid-argon calorimeters under high pile-up conditions expected at the HL-LHC is presented. These networks are designed to run on the FPGA-based readout hardware of the calorimeters under strict size and latency constraints. Several architectures, including Dense, Recurrent (RNN), and Convolutional (CNN) neural networks, are optimised using a Bayesian procedure that balances energy resolution against network size. The optimised Dense, CNN, and combined Dense+RNN architectures achieve a transverse energy resolution of approximately 80 MeV, outperforming both the optimal filtering (OF) method currently in use and RNNs of similar complexity. A detailed comparison across the full dynamic range shows that Dense, CNN, and Dense+RNN accurately reproduce the energy scale, while OF and RNNs underestimate the energy. Deep Evidential Regression is implemented within the Dense architecture to address the need for reliable per-event energy uncertainties. This approach provides predictive uncertainty estimates with minimal increase in network size. The predicted uncertainty is found to be consistent, on average, with the difference between the true deposited energy and the predicted energy.",2025,"['Georges Aad', 'Raphael Bertrand', 'Lauri Laatu', 'Emmanuel Monnier', 'Arno Straessner', 'Nairit Sur', 'Johann C. Voigt']",http://arxiv.org/abs/2510.11469v1,arxiv,,,,,,,2510.11469v1,,True
,,Improved Pixel-wise Calibration for Charge-Integrating Hybrid Pixel   Detectors with Performance Validation,"The M\""ONCH hybrid pixel detector, with a 25 \textmu m pixel pitch and fast charge-integrating readout, has demonstrated subpixel resolution capabilities for X-ray imaging and deep learning-based electron localization in electron microscopy. Fully exploiting this potential requires extensive calibration to ensure both linearity and uniformity of the pixel response, which is challenging for detectors with a large dynamic range. To overcome the limitations of conventional calibration methods, we developed an accurate and efficient correction method to achieve pixel-wise gain and nonlinearity calibration based on the backside pulsing technique. A three-dimensional lookup table was generated for all pixels across the full dynamic range, mapping the pixel response to a calibrated linear energy scale. Compared with conventional linear calibration, the proposed method yields negligible deviations between the calibrated and nominal energies for photons and electrons. The improvement in energy resolution ranges from 4% to 22% for 15-25 keV photons and from 16% to 23% for 60-200 keV electrons. Deep learning-based electron localization demonstrates a 4% improvement in spatial resolution when using the proposed calibration method. This approach further enables rapid diagnosis of the cause of bad pixels and estimation of bump-bonding yield.",2025,"['X. Xie', 'A. Bergamaschi', 'M. Brückner', 'M. Carulla', 'R. Dinapoli', 'S. Ebner', 'K. Ferjaoui', 'E. Fröjdh', 'V. Gautam', 'D. Greiffenberg', 'S. Hasanaj', 'J. Heymes', 'V. Hinger', 'M. Hürst', 'V. Kedych', 'T. King', 'S. Li', 'C. Lopez-Cuenca', 'A. Mazzoleni', 'D. Mezza', 'K. Moustakas', 'A. Mozzanica', 'J. Mulvey', 'M. Müller', 'K. A. Paton', 'C. Posada Soto', 'C. Ruder', 'B. Schmitt', 'P. Sieber', 'S. Silletta', 'D. Thattil', 'J. Zhang']",http://arxiv.org/abs/2510.11024v1,arxiv,,,,,,,2510.11024v1,,True
,,Topological Landscapes of the BSM Higgs Sector,"We explore the structure of the parameter space in the Singlet Scalar Dark Matter (SSDM) model and the Next-to-Two Higgs Doublet Model (N2HDM) with $\tan\beta = 5$ and $\tan\beta = 45$. Parameter points are classified as allowed or excluded based on compatibility with the Higgs observation constraints. Using a combined framework of Topological Data Analysis (TDA), Uniform Manifold Approximation and Projection (UMAP), and Linear Discriminant Analysis (LDA), we characterize the global geometry and topology of these high-dimensional landscapes. Our findings reveal that the SSDM and the N2HDM Type~I model exhibit finely tuned islands of collider viability. In the case of N2HDM Type~I, we also find that increasing $\tan\beta$ leads to greater topological fragmentation and higher Betti number persistence, indicating enhanced structural complexity. In contrast, the given choice of parameters excludes the entire N2HDM Type II parameter space based on current Higgs measurements. The topological properties serve as important quantitative descriptors for the phenomenological viability of the BSM frameworks. We leverage the above mentioned topological features to train machine learning models for faster characterization of the BSM Higgs sector into allowed and excluded parameter regions.",2025,['Jyotiranjan Beuria'],http://arxiv.org/abs/2510.10900v1,arxiv,,,,,,,2510.10900v1,,True
,,A family of three maximally symmetric boost-invariant flows in   relativistic hydrodynamics,"I discuss the constructions of boost-invariant dissipative conformal hydrodynamic flows by elaborating on the geometric procedure by Gubser and Yarom, which starts from a static, maximally symmetric flow on dS$_3\times\mathbb{R}$. Three foliations of dS$_3$ preserve three-dimensional non-Abelian isometry groups, namely, the flat ISO(2)-invariant, the spherical (closed) SO(3)-invariant, and the hyperbolic (open) SO(2,1)-invariant slicings. I show that the fluids that preserve these symmetries, after they have been Weyl transformed to flat spacetime, give rise to three physically distinct and boost-invariant solutions of the relativistic dissipative Navier-Stokes equations: the well-known and widely studied Bjorken and Gubser flows, and a seemingly thus far unexplored solution that arises from the hyperbolic slicing of dS$_3$. The new solution combines the radial expansion characteristic of the Gubser flow with the late-proper-time applicability of Bjorken's solution, and features a finite, radially bounded droplet whose expanding edge resembles a free-streaming shockwave.",2025,['Sašo Grozdanov'],http://arxiv.org/abs/2510.10769v1,arxiv,,,,,,,2510.10769v1,,False
,,Enhancing Phase Transition Calculations with Fitting and Neural Network,"The computation of bounce action in a phase transition involves solving partial differential equations, inherently introducing non-negligible numerical uncertainty. Deriving characteristic temperatures and properties of this transition necessitates both differentiation and integration of the action, thereby exacerbating the uncertainty. In this work, we fit the action curve as a function of temperature to mitigate the uncertainties inherent in the calculation of the phase transition parameters. We find that, after extracting a factor, the sixth-order polynomial yields an excellent fit for the action in the high temperature approximated potential. In a realistic model, the singlet extension of the Standard Model, this method performs satisfactorily across most of the parameter space after trimming the fitting data. This approach not only enhances the accuracy of phase transition calculations but also systematically reduces computation time and facilitates error estimation, particularly in models involving multiple scalar fields. Furthermore, we discussed the possible of using multiple neural networks to predict the action curve from model parameters.",2025,"['Ligong Bian', 'Hongxin Wang', 'Yang Xiao', 'Ji-Chong Yang', 'Jin Min Yang', 'Yang Zhang']",http://arxiv.org/abs/2510.10667v1,arxiv,,,,,,,2510.10667v1,,True
,,dN/dx Reconstruction with Deep Learning for High-Granularity TPCs,"Particle identification (PID) is essential for future particle physics experiments such as the Circular Electron-Positron Collider and the Future Circular Collider. A high-granularity Time Projection Chamber (TPC) not only provides precise tracking but also enables dN/dx measurements for PID. The dN/dx method estimates the number of primary ionization electrons, offering significant improvements in PID performance. However, accurate reconstruction remains a major challenge for this approach. In this paper, we introduce a deep learning model, the Graph Point Transformer (GraphPT), for dN/dx reconstruction. In our approach, TPC data are represented as point clouds. The network backbone adopts a U-Net architecture built upon graph neural networks, incorporating an attention mechanism for node aggregation specifically optimized for point cloud processing. The proposed GraphPT model surpasses the traditional truncated mean method in PID performance. In particular, the $K/\pi$ separation power improves by approximately 10% to 20% in the momentum interval from 5 to 20 GeV/c.",2025,"['Guang Zhao', 'Yue Chang', 'Jinxian Zhang', 'Linghui Wu', 'Huirong Qi', 'Xin She', 'Mingyi Dong', 'Shengsen Sun', 'Jianchun Wang', 'Yifang Wang', 'Chunxu Yu']",http://arxiv.org/abs/2510.10628v2,arxiv,,,,,,,2510.10628v2,,True
,,Integrability in Three-Dimensional Gravity: Eigenfunction-Forced KdV   Flows,"We uncover a direct connection between three-dimensional gravity with chiral boundary conditions and a class of forced integrable systems. Starting from the Chern-Simons formulation, we derive consistent boundary conditions on a non-compact spatial slice, leading to boundary dynamics described by the potential modified KdV hierarchy. The dynamics reduce to a forced KdV equation, where the forcing term is determined self-consistently by the eigenfunctions of the associated Schr\""{o}dinger operator. Using the inverse scattering transform, the reflectionless sector is solved via the Gelfand-Levitan-Marchenko method, while the radiative sector exhibits universal dispersive decay. This framework unifies AdS$_3$ boundary dynamics with integrable hierarchies and elucidates the roles of solitons and radiation in the dual conformal field theory.",2025,"['Hamed Adami', 'Anousheh Latifi']",http://arxiv.org/abs/2510.10519v1,arxiv,,,,,,,2510.10519v1,,False
,,Quantum Integration Networks for Efficient Monte Carlo in High-Energy   Physics,"Monte Carlo methods play a central role in particle physics, where they are indispensable for simulating scattering processes, modeling detector responses, and performing multi-dimensional integrals. However, traditional Monte Carlo methods often suffer from slow convergence and insufficient precision, particularly for functions with singular features such as rapidly varying regions or narrow peaks. Quantum circuits provide a promising alternative: compared to conventional neural networks, they can achieve rich expressivity with fewer parameters, and the parameter-shift rule provides an exact analytic form for circuit gradients, ensuring precise optimization. Motivated by these advantages, we investigate how sampling strategies and loss functions affect integration efficiency within the \textbf{Quantum Integration Network} (QuInt-Net). We compare adaptive and non-adaptive sampling approaches and examine the impact of different loss functions on accuracy and convergence. Furthermore, we explore three quantum circuit architectures for numerical integration: the data re-uploading model, the quantum signal processing protocol, and deterministic quantum computation with one qubit. The results provide new insights into optimizing QuInt-Nets for applications in high energy physics.",2025,"['Heechan Yi', 'Kayoung Ban', 'Myeonghun Park', 'Kyoungchul Kong']",http://arxiv.org/abs/2510.10501v1,arxiv,,,,,,,2510.10501v1,,True
,,New Evidence for Extragalactic Einstein Probe Transients associated with   Long Gamma-ray Bursts,"The origin of extragalactic fast X-ray transients (EFXTs) remains a fundamental open question in high-energy astrophysics. The Einstein Probe (EP) mission provides a transformative opportunity to investigate their nature. While mounting observations of EP-discovered EFXTs (EP-EFXTs) suggest a possible connection to long gamma-ray bursts (lGRBs), an in-depth comparative analysis between them remains lacking. Here, we present a comparative analysis of their cosmic formation histories, revealing that EP-EFXTs and lGRBs share a similar evolutionary trend-showing a marked decline at $z<1.0$ and a plateau beyond $1.0<z<5$-which clearly distinguishes them from short GRBs. This result is derived from a rigorously selected sample of EP-EFXTs, using Lynden-Bell's $c^{-}$ method to reconstruct, for the first time, the luminosity function and formation rate of EP-EFXTs without any assumptions. Our findings provide independent evidence that EP-EFXTs and lGRBs may originate from a common progenitor channel.",2025,"['Qin-Mei Li', 'Qi-Bin Sun', 'Sheng-Bang Qian', 'Fu-Xing Li']",http://arxiv.org/abs/2510.10267v1,arxiv,,,,,,,2510.10267v1,,False
,,Scaling properties of nuclear parton distributions in   short-range-correlation motivated two-component parametrization,"We provide some critical remarks on the recently proposed two-component parametrization of nuclear parton distribution functions, which was motivated by the apparent correlation between the nuclear modifications of structure functions and nucleon-nucleon short-range correlation phenomena. This parametrization, we show, is invariant under a rescaling transformation of the involved abundance coefficients, which means that the global normalization of these coefficients cannot be meaningfully determined in a fit, and only their ratios should be studied for finding evidence of short-range-correlation type behavior at parton level. As we show, however, the current constraints for the nuclear-mass dependence of these coefficients allow also for interpretations different from short-range correlations. Nevertheless, this two-component parametrization exhibits a similar scaling relation for DIS structure functions as demonstrated in earlier works, and, as we demonstrate, yields testable predictions for structure-function and hard-process cross-section ratios. We also note on the non-trivial isospin dependence of the short-range-correlation motivated parametrization, which under proton-neutron pair dominance assumption can lead to charge-symmetry-violation resembling terms.",2025,['Petja Paakkinen'],http://arxiv.org/abs/2510.00252v1,arxiv,,,,,,,2510.00252v1,,False
,,Real-time Anomaly Detection for Liquid Argon Time Projection Chambers,"We present a real-time anomaly detection framework for liquid argon time projection chambers (LArTPCs), targeting applications in particle physics experiments such as the Short Baseline Near Detector (SBND) or the future Deep Underground Neutrino Experiment (DUNE). These experiments employ detectors that generate and stream high-resolution but sparse images of neutrino and other particle interactions. Our approach utilizes anomaly detection with autoencoders, compressed through knowledge distillation (KD), to enable the detection of anomalous signals in the data through efficient inference on resource-constrained hardware. The framework is targeted for deployment on computing platforms equipped with field-programmable gate arrays (FPGAs), GPUs, or CPUs, allowing low-latency selection of relevant activity directly from the raw detector data stream. We demonstrate that our approach is suitable for the detection and localization of anomalously ""high-multiplicity"" activity, and outline promising applications for LArTPC online data filtering and triggering.",2025,"['Seokju Chung', 'Jack Cleeve', 'Akshay Malige', 'Georgia Karagiorgi', 'Lino Gerlach', 'Adrian A. Pol', 'Isobel Ojalvo']",http://arxiv.org/abs/2509.21817v1,arxiv,,,,,,,2509.21817v1,,True
,,"Flavour, Accidentally","We propose a new class of flavour models in which the spurion which breaks Standard Model flavour symmetries transforms in a non-minimal representation. Hierarchies in fermion masses, which arise from multiple insertions of this spurion, may be generated in a technically natural, accidental manner, from a handful of untuned $\mathcal{O}(1)$ elements in the UV. This relies explicitly on the non-Abelian nature of the symmetry, distinguishing it from standard Froggatt-Nielsen-like scenarios. The pattern of flavour violating operators at dimension-6 can radically differ from previously considered scenarios, and emphasises the need for a broad flavour programme across all generations.",2025,"['Hannah Banks', 'Graeme Crawford', 'Matthew McCullough', 'Dave Sutherland']",http://arxiv.org/abs/2510.03403v1,arxiv,,,,,,,2510.03403v1,,False
,,Stable and Interpretable Jet Physics with IRC-Safe Equivariant Feature   Extraction,"Deep learning has achieved remarkable success in jet classification tasks, yet a key challenge remains: understanding what these models learn and how their features relate to known QCD observables. Improving interpretability is essential for building robust and trustworthy machine learning tools in collider physics. To address this challenge, we investigate graph neural networks for quark-gluon discrimination, systematically incorporating physics-motivated inductive biases. In particular, we design message-passing architectures that enforce infrared and collinear (IRC) safety, as well as E(2) and O(2) equivariance in the rapidity-azimuth plane. Using simulated jet datasets, we compare these networks against unconstrained baselines in terms of classification performance, robustness to soft emissions, and latent representation structures. Our analysis shows that physics-aware networks are more stable across training instances and distribute their latent variance across multiple interpretable directions. By regressing Energy Flow Polynomials onto the leading principal components, we establish a direct correspondence between learned representations and established IRC-safe jet observables. These results demonstrate that embedding symmetry and safety constraints not only improves robustness but also grounds network representations in known QCD structures, providing a principled approach toward interpretable deep learning in collider physics.",2025,"['Partha Konar', 'Vishal S. Ngairangbam', 'Michael Spannowsky', 'Deepanshu Srivastava']",http://arxiv.org/abs/2509.22059v1,arxiv,,,,,,,2509.22059v1,,True
,,Wasserstein normalized autoencoder for anomaly detection,"A novel anomaly detection algorithm is presented. The Wasserstein normalized autoencoder (WNAE) is a normalized probabilistic model that minimizes the Wasserstein distance between the learned probability distribution -- a Boltzmann distribution where the energy is the reconstruction error of the autoencoder -- and the distribution of the training data. This algorithm has been developed and applied to the identification of semivisible jets -- conical sprays of visible standard model particles and invisible dark matter states -- with the CMS experiment at the CERN LHC. Trained on jets of particles from simulated standard model processes, the WNAE is shown to learn the probability distribution of the input data in a fully unsupervised fashion, such that it effectively identifies new physics jets as anomalies. The model consistently demonstrates stable, convergent training and achieves strong classification performance across a wide range of signals, improving upon standard normalized autoencoders, while remaining agnostic to the signal. The WNAE directly tackles the problem of outlier reconstruction, a common failure mode of autoencoders in anomaly detection tasks.",2025,['CMS Collaboration'],http://arxiv.org/abs/2510.02168v1,arxiv,,,,,,,2510.02168v1,,True
,,From gauging to duality in one-dimensional quantum lattice models,"Gauging and duality transformations, two of the most useful tools in many-body physics, are shown to be equivalent up to constant depth quantum circuits in the case of one-dimensional quantum lattice models. This is demonstrated by making use of matrix product operators, which provide the lattice representation theory for global (categorical) symmetries as well as a classification of duality transformations. Our construction makes the symmetries of the gauged theory manifest and clarifies how to deal with static background fields when gauging generalised symmetries.",2025,"['Bram Vancraeynest-De Cuiper', 'José Garre-Rubio', 'Frank Verstraete', 'Kevin Vervoort', 'Dominic J. Williamson', 'Laurens Lootens']",http://arxiv.org/abs/2509.22051v1,arxiv,,,,,,,2509.22051v1,,False
,,Machine learning in lattice quantum gravity,"Using numerical data coming from Monte Carlo simulations of four-dimensional Causal Dynamical Triangulations, we study how automated machine learning algorithms can be used to recognize transitions between different phases of quantum geometries observed in lattice quantum gravity. We tested seven supervised and seven unsupervised machine learning models and found that most of them were very successful in that task, even outperforming standard methods based on order parameters.",2025,"['Jan Ambjorn', 'Zbigniew Drogosz', 'Jakub Gizbert-Studnicki', 'Andrzej Görlich', 'Dániel Németh', 'Marcus Reitz']",http://arxiv.org/abs/2510.02159v1,arxiv,,,,,,,2510.02159v1,,True
,,Machine Learning for Event Reconstruction in the CMS Phase-2 High   Granularity Calorimeter Endcap,"The high-luminosity era of the LHC will offer greatly increased number of events for more precise Standard Model measurements and Beyond Standard Model searches, but will also pose unprecedented challenges to the detectors. To meet these challenges, the CMS detector will undergo several upgrades, including the replacement of the current endcap calorimeters with a novel High-Granularity Calorimeter (HGCAL). To make optimal use of this innovative detector, new and original algorithms are being devised. A dedicated reconstruction framework, The Iterative Clustering (TICL), is being developed within the CMS Software (CMSSW). This new framework is designed to fully exploit the high spatial resolution and precise timing information provided by HGCAL. Several key ingredients of the object reconstruction chain already rely on Machine Learning (ML) techniques and their usage is expected to further develop in the future. The existing reconstruction strategies will be presented stressing the role played by ML techniques to exploit the information provided by the detector. The areas where ML techniques are expected to play a role in the future developments will be also discussed.",2025,['Théo Cuisset'],http://arxiv.org/abs/2510.01851v1,arxiv,,,,,,,2510.01851v1,,True
,,Reducing Simulation Dependence in Neutrino Telescopes with Masked Point   Transformers,"Machine learning techniques in neutrino physics have traditionally relied on simulated data, which provides access to ground-truth labels. However, the accuracy of these simulations and the discrepancies between simulated and real data remain significant concerns, particularly for large-scale neutrino telescopes that operate in complex natural media. In recent years, self-supervised learning has emerged as a powerful paradigm for reducing dependence on labeled datasets. Here, we present the first self-supervised training pipeline for neutrino telescopes, leveraging point cloud transformers and masked autoencoders. By shifting the majority of training to real data, this approach minimizes reliance on simulations, thereby mitigating associated systematic uncertainties. This represents a fundamental departure from previous machine learning applications in neutrino telescopes, paving the way for substantial improvements in event reconstruction and classification.",2025,"['Felix J. Yu', 'Nicholas Kamp', 'Carlos A. Argüelles']",http://arxiv.org/abs/2510.01733v1,arxiv,,,,,,,2510.01733v1,,True
,,Temperature derivative divergence of the electric conductivity and   thermal photon emission rate at the critical end point from holography,"The thermal photon emission rate $\frac{d\Gamma}{dk}$ and DC eletric conductivity $\sigma_{Q}$ of the strongly coupled quark-gluon plasma (sQGP) are investigated around the critical end point in a $N_f=2+1$ holographic QCD model with parameters obtained from machine-learning. It is found that both thermal photon emission rate and eletric conductivity grow most obviously around $T_c$, which agrees with the previous studies, and the result of eletric conductivity at zero chemical potential resembles the lattice results. Moreover, it is found that both the temperature derivative of the eletric conductivity and thermal photon emission rate diverge at the critical end point.",2025,"['Yi-Ping Si', 'Danning Li', 'Mei Huang']",http://arxiv.org/abs/2509.25636v1,arxiv,,,,,,,2509.25636v1,,False
,,Automating Sensor Characterization with Bayesian Optimization,"The development of novel instrumentation requires an iterative cycle with three stages: design, prototyping, and testing. Recent advancements in simulation and nanofabrication techniques have significantly accelerated the design and prototyping phases. Nonetheless, detector characterization continues to be a major bottleneck in device development. During the testing phase, a significant time investment is required to characterize the device in different operating conditions and find optimal operating parameters. The total effort spent on characterization and parameter optimization can occupy a year or more of an expert's time. In this work, we present a novel technique for automated sensor calibration that aims to accelerate the testing stage of the development cycle. This technique leverages closed-loop Bayesian optimization (BO), using real-time measurements to guide parameter selection and identify optimal operating states. We demonstrate the method with a novel low-noise CCD, showing that the machine learning-driven tool can efficiently characterize and optimize operation of the sensor in a couple of days without supervision of a device expert.",2025,"['J. Cuevas-Zepeda', 'C. Chavez', 'J. Estrada', 'J. Noonan', 'B. D. Nord', 'N. Saffold', 'M. Sofo-Haro', 'R. Spinola e Castro', 'S. Trivedi']",http://arxiv.org/abs/2509.21661v1,arxiv,,,,,,,2509.21661v1,,True
,,Addressing the sign-problem in Euclidean path integrals with radial   basis function neural networks,"Solving interacting field theories at finite densities remains a numerically and conceptually challenging task, even with modern computational capabilities. In this paper, we propose a novel approach based on an expansion of the Euclidean path integrals using radial basis function neural networks, which allows the calculation of observables at finite densities and overcomes the sign problem in a numerically very efficient manner. The method is applied to an interacting complex scalar field theory at finite chemical potential in 3+1 dimensions, which exhibits both the sign problem and the silver blaze phenomenon, similar to QCD. The critical chemical potential at which phase transition occurs is estimated to be $\mu_c=1.17 \pm 0.018$, and the silver blaze problem is accurately described below $\mu_c$.",2025,['Gabor Balassa'],http://arxiv.org/abs/2510.01695v2,arxiv,,,,,,,2510.01695v2,,True
,,Dirac QNM spectrum from twisted semiclassical gauge theory of gravity,"Twisted Abelian gauge theory coupled to a noncommutative (NC) Dirac field is studied in order to infer   the quasinormal mode (QNM) spectrum of the fermion matter perturbations in the vicinity of the Reissner-Nordstr\""om (RN) black hole. The action functional of the theory is invariant under the truncated NC local $U(1)_{\star}$ gauge transformations that keep the gravitational background intact. The latter, being a classical gravitational background unaffected by the   NC local gauge transformations, makes the theory semiclassical. The most prominent feature of the QNM spectrum is the splitting in the total angular momentum projection due to the noncommutativity induced $SO(3) \rightarrow U(1)$ symmetry breaking pattern.",2025,"['Marija Dimitrijević Ćirić', 'Nikola Herceg', 'Nikola Konjik', 'A. Naveena Kumara', 'Andjelo Samsarov']",http://arxiv.org/abs/2509.21620v1,arxiv,,,,,,,2509.21620v1,,False
,,Gravitational wave experiments: achievements and plans,"Gravitational wave (GW) experiments have transformed our understanding of the Universe by enabling direct observations of compact object mergers and other astrophysical phenomena. This chapter reviews the concepts of GW detectors, such as LIGO, Virgo, and KAGRA, and describes their operating principles, data acquisition and analysis techniques, and some of the methods used to extract source properties. The scientific impact of GW observations is discussed as well, including contributions to astrophysics, tests of general relativity, and cosmology. We also examine the role of multimessenger astronomy and the complementarity between different GW detectors and with other astroparticle experiments. Finally, we outline future prospects with next-generation detectors, like the Einstein Telescope and Cosmic Explorer, and space-based missions.",2025,"['Elisa Bigongiari', 'Matteo Di Giovanni', 'Giovanni Losurdo']",http://arxiv.org/abs/2509.25952v2,arxiv,,,,,,,2509.25952v2,,False
,,Foundation models for high-energy physics,"The rise of foundation models -- large, pretrained machine learning models that can be finetuned to a variety of tasks -- has revolutionized the fields of natural language processing and computer vision. In high-energy physics, the question of whether these models can be implemented directly in physics research, or even built from scratch, tailored for particle physics data, has generated an increasing amount of attention. This review, which is the first on the topic of foundation models in high-energy physics, summarizes and discusses the research that has been published in the field so far.",2025,['Anna Hallin'],http://arxiv.org/abs/2509.21434v1,arxiv,,,,,,,2509.21434v1,,True
,,Primordial black holes formation in inflationary $F(R)$ models with   scalar fields,"We construct $F(R)$ gravity models with scalar fields to describe cosmological inflation and formation of primordial black holes (PBHs). By adding the induced gravity term and the fourth-order polynomial potential for the scalar field to the known $F(R)$ gravity model, and using a conformal transformation of the metric, we obtain a two-field chiral cosmological model. For some values of the model parameters, we get that the inflationary parameters of this model are in good agreement with the observations of the cosmic microwave background radiation obtained by the Atacama Cosmology Telescope. The estimation of PBH masses suggests that PBHs could be dark matter candidates.",2025,"['E. O. Pozdeeva', 'S. Yu. Vernov']",http://arxiv.org/abs/2509.21220v1,arxiv,,,,,,,2509.21220v1,,False
,,Small-$b$ expansion of the DOZZ formula for light operators,"We present a systematic small-$b$ expansion of the Liouville DOZZ three-point structure constant in the light-operator regime $\alpha_i = b\sigma_i$ as $b\to 0$. In this limit, the exact DOZZ function factorizes into a prefactor $\mathcal{P}(b;\sigma_1,\sigma_2,\sigma_3)$ and a power series in $b^2$, \[ C(b\sigma_1,b\sigma_2,b\sigma_3) =\mathcal{P}(b;\sigma_i)\Bigl[1+\sum_{n=1}^\infty b^{2n}\,\Omega_n(\sigma_1,\sigma_2,\sigma_3)\Bigr]. \] Using Thorn's asymptotic expansion of the $\Upsilon_b$-function, we derive closed-form expressions for the leading coefficients $\Omega_n(\sigma_i)$ and show that each $\Omega_n$ is a symmetric polynomial in the variables $\sigma_i$. Our expansion provides explicit perturbative corrections to the semiclassical Liouville three-point function and therefore supplies a practical tool for applications in celestial holography, in particular, for generating loop-level corrections to the tree-level three-gluon scattering amplitude using the inverse Mellin transform. We conclude by outlining these directions for further development. In particular, we highlight that a primary next step is to extend this framework to four-point amplitudes.",2025,"['Franco Ferrari', 'Marcin R. Piatek', 'Artur R. Pietrykowski']",http://arxiv.org/abs/2509.21182v1,arxiv,,,,,,,2509.21182v1,,False
,,T-duality and bosonization as examples of continuum gauging and   disentangling,"Dualities and duality transformations form a well established methodology in various aspects of quantum many body physics and quantum field theories, allowing one to exploit equivalence between models which may naively seem completely different in order to gain access to further physical regimes, either analytically, numerically or experimentally. Recently, in the context of condensed matter physics and quantum information, it was shown that dualities can be understood very well through a gauging and disentangling procedure that can be represented by a finite depth quantum circuit. In this letter we expand these concepts to the continuum, suggesting them as a way to derive duality transformations in continuum field theories and particle physics, and benchmark the presented ideas through the re-derivation of T-duality and bosonization.",2025,"['Gertian Roose', 'Erez Zohar']",http://arxiv.org/abs/2509.24630v1,arxiv,,,,,,,2509.24630v1,,False
,,Design and deployment of a fast neural network for measuring the   properties of muons originating from displaced vertices in the CMS Endcap   Muon Track Finder,"We report on the development, implementation, and performance of a fast neural network used to measure the transverse momentum in the CMS Level-1 Endcap Muon Track Finder. The network aims to improve the triggering efficiency of muons produced in the decays of long-lived particles (LLPs). We implemented it in firmware for a Xilinx Virtex-7 FPGA and deployed it during the LHC Run 3 data-taking in 2023. The new displaced muon triggers that use this algorithm broaden the phase space accessible to the CMS experiment for searches that look for evidence of LLPs that decay into muons.",2025,['Efe Yigitbasi'],http://arxiv.org/abs/2509.21062v2,arxiv,,,,,,,2509.21062v2,,True
,,Fair Universe Higgs Uncertainty Challenge,"This competition in high-energy physics (HEP) and machine learning was the first to strongly emphasise uncertainties in $(H \rightarrow \tau^+ \tau^-)$ cross-section measurement. Participants were tasked with developing advanced analysis techniques capable of dealing with uncertainties in the input training data and providing credible confidence intervals. The accuracy of these intervals was evaluated using pseudo-experiments to assess correct coverage. The dataset is now published in Zenodo, and the winning submissions are fully documented.",2025,"['Ragansu Chakkappai', 'Wahid Bhimji', 'Paolo Calafiura', 'Po-Wen Chang', 'Yuan-Tang Chou', 'Sascha Diefenbacher', 'Jordan Dudley', 'Steven Farrell', 'Aishik Ghosh', 'Isabelle Guyon', 'Chris Harris', 'Shih-Chieh Hsu', 'Elham E. Khoda', 'Benjamin Nachman', 'Peter Nugent', 'David Rousseau', 'Benjamin Thorne', 'Ihsan Ullah', 'Yulei Zhang']",http://arxiv.org/abs/2509.22247v1,arxiv,,,,,,,2509.22247v1,,True
,,X-ray and neural network based in-situ identification of the melt pool   during the additive manufacturing of a stainless steel part,"Laser Metal Deposition with Powder (LMDp) is an additive manufacturing technique used for repairing metal components or producing parts with intricate geometries. However, a comprehensive understanding of the melt pool dynamics, which significantly influences the final properties of LMDp-fabricated parts, remains limited. Non-destructive testing is highly valuable for conducting in-situ controls during manufacturing. X-ray imaging offers the ability to penetrate metallic parts and detect defects such as porosity. In the context of additive manufacturing, X-rays can be employed to visualize the shape of the melt pool during the fabrication process. The contrast between the liquid and solid phases, due to their density differences, should be observable in the radioscopy images. The experimental setup required to perform such a test on an industrial additive manufacturing installation consists of a movable X-ray source that produces polychromatic beams, a detector, and extensive lead shielding to ensure X-ray safety. In-situ observations of the melt pool were conducted during the deposition of ten successive layers of stainless steel 316L (SS316L). The polychromatic nature of the X-ray beam, however, rendered traditional image analysis methods ineffective for detecting contrast variations. To address this challenge, neural networks trained on simulated data (thermal and X-ray) were employed, providing a solution to identify the melt pool in low-contrast radioscopic images. The architecture inspired by VGG16 demonstrated promising results, confirming the potential for in-situ non-destructive testing using X-ray imaging in industrial additive manufacturing processes.",2025,"['Loic Jegou', 'Valerie Kaftandjian', 'Thomas Elguedj', 'Mohamed Tahraoui', 'Philippe Duvauchelle', 'Mady Guillemot']",http://arxiv.org/abs/2509.22409v1,arxiv,,,,,,,2509.22409v1,,True
,,"Predictions with limited data: Bayesian (X)PINNs, entanglement surfaces   and overconfidence","Solving differential equations from limited or noisy data remains a key challenge for physics-informed neural networks (PINNs), which are typically applied to already known and smooth solutions. In this work, we explore Bayesian PINNs and extended PINNs, (B-(X)PINNs), to solve non-linear second order differential equation typical for high energy theory, where data is only available from the boundary domain, to benchmark suitable approaches to PINNs in this category. In particular, we consider an entangling surface; a differential equation typical in holography. We perform asymptotic analysis to generate analytical training data from the boundary domain. We also explore the meaning of overconfidence in models that are constrained by physical priors and argue that standard overconfidence metrics are not suitable to consider when dealing with B-PINNs. Overconfidence can be a natural feature and not a bug in systems with soft or hard constraints on the loss function; one have to look at when the overconfidence is an artifact of the model adhering to the physics constraints. To diagnose this effect, we introduce an information density quantity, and a local physics-constraint coupling (PCC) metric, to capture locally to what extent the enforced physics collapses the posterior distribution. We also consider these quantities for a Liouville-type equation and the Van der Pol equation to probe apparent overconfidence further.",2025,"['Filip Landgren', 'Marika Taylor']",http://arxiv.org/abs/2509.23784v1,arxiv,,,,,,,2509.23784v1,,True
,,Residual Symmetries and BRST Cohomology of Schwarzschild in the   Kerr-Schild Double Copy,"The Kerr-Schild (KS) double copy is celebrated for producing exact gravitational spacetimes from gauge fields, yet the preservation of symmetry content remains largely unexplored. We investigate the fate of residual symmetries in the KS double copy, focusing on the Schwarzschild solution. On the gauge theory side, we derive the residual transformations that preserve the Abelian and non-Abelian KS ansatz\""e, finding they both form an infinite-dimensional Lie algebra parameterized by arbitrary null functions. On the gravity side, we analyze the resulting residual diffeomorphisms of the KS Schwarzschild metric. Restricting our focus to the Killing vector class of solutions, we find that the only surviving diffeomorphisms are the finite-dimensional global isometries of Schwarzschild, reducing the residual gauge algebra to the subalgebra generated by time translations and spatial rotations. This finding reveals a fundamental structural mismatch: the infinite-dimensional algebra of the gauge side admits no simple counterpart in this constrained gravitational sector. We formalize this by showing that the BRST operator for the residual symmetry is trivialized under the Killing condition. This result serves as a crucial consistency check, validating the kinematic algebraic collapse within a quantum field theoretic framework. This paper is the first of a two-part series. In the second paper, we complete this analysis by examining the more complex proper conformal Killing vector (CKV) class of solutions and formulating a unified BRST framework to definitively test the structural obstruction.",2025,['Brandon Holton'],http://arxiv.org/abs/2509.24112v6,arxiv,,,,,,,2509.24112v6,,False
,,Applications of Machine Learning in Constraining Multi-Scalar Models,"Machine learning techniques are used to predict theoretical constraints such as unitarity and boundedness from below in extensions of the Standard Model. This approach has proven effective for models incorporating additional SU(2) scalar multiplets, in particular the quadruplet and sixplet cases. High predictive performance is achieved through the use of suitable neural network architectures and well-prepared training datasets. Moreover, machine learning provides a substantial computational advantage, enabling significantly faster evaluations compared to scalar potential minimization.",2025,['Darius Jurčiukonis'],http://arxiv.org/abs/2509.24092v1,arxiv,,,,,,,2509.24092v1,,True
,,Wafer-Level Prototyping Tools for CMOS Bioelectronic Sensors,"Integrating biology with complementary metal-oxide-semiconductor (CMOS) sensors can enable highly parallel measurements with minimal parasitic effects, significantly enhancing sensitivity. However, realizing this potential often requires overcoming substantial barriers related to design, fabrication, and heterogeneous integration. In this context, we present a comprehensive suite of tools and methods designed for wafer-scale biosensor prototyping that is sensitive, highly parallelizable, and manufacturable. A central component of our approach is a new initiative that allows for open-source multi-project wafers (MPW), giving all participants access to the designs submitted by others. We demonstrate that this strategy not only promotes design reuse but also facilitates advanced back-end-of-line (BEOL) fabrication techniques, improving the manufacturability and process yield of CMOS biosensors. Developing CMOS-based biosensors also involves the challenge of heterogeneous integration, which includes external electrical, mechanical, and fluid layers. We demonstrate simple modular designs that enable such integration for sample delivery and signal readout. Finally, we showcase the effectiveness of our approach in measuring the hybridization of DNA molecules by focusing on data acquisition and machine learning (ML) methods that leverage the parallelism of the sensors to enable robust classification of desirable analyte interactions.",2025,"['Advait Madhavan', 'Ruohong Shi', 'Alokik Kanwal', 'Glenn Holland', 'Jacob M. Majikes', 'Paul N. Patrone', 'Anthony J. Kearsley', 'Arvind Balijepalli']",http://arxiv.org/abs/2509.24075v1,arxiv,,,,,,,2509.24075v1,,True
,,Unsupervised Machine Learning for Anomaly Detection in LHC Collider   Searches,"Searches for new physics at the LHC at CERN traditionally use advanced simulations to model Standard Model and new-physics processes in high-energy collisions and compare them with data. The lack of recent direct discoveries, however, has motivated the development of model-independent approaches in HEP to complement existing hypothesis-driven analyses, particularly Anomaly Detection. A review of the latest efforts in BSM searches with anomaly detection is presented in these proceedings, focusing on contributions within the ATLAS collaboration at LHC and discussing Variational Recurrent Neural Network, Deep Transformer and Graph Anomaly Detection applications.",2025,"[""Antonio D'Avanzo""]",http://arxiv.org/abs/2509.24723v1,arxiv,,,,,,,2509.24723v1,,True
,,Predicting the single-site and multi-site event discrimination power of   dual-phase time projection chambers,"Dual-phase xenon time projection chambers (TPCs) are widely used in searches for rare dark matter and neutrino interactions, in part because of their excellent position reconstruction capability in 3D. Despite their millimeter-scale resolution along the charge drift axis, xenon TPCs face challenges in resolving single-site (SS) and multi-site (MS) interactions in the transverse plane. In this paper, we build a generic TPC model with an idealized light-based signal readout, and use Fisher Information (FI) to study its theoretical capability of differentiating SS and MS events. We also demonstrate via simulation that this limit can be approached with conventional reconstruction algorithms like maximum likelihood estimation, and with a convolutional neural network classifier. The implications of this study on future TPC experiments will be discussed.",2025,"['A. B. M. Rafi Sazzad', 'Clarke A. Hardy', 'Xiang Dai', 'Jingke Xu', 'Brian G. Lenardo', 'Felicia Sutanto', 'Nicholas A. Antipa', 'Jeremy D. Koertzen', 'Prince John', 'Abraham Akinin', 'Teal J. Pershing']",http://arxiv.org/abs/2510.02258v2,arxiv,,,,,,,2510.02258v2,,True
,,High Luminosity LHC data collected by CMS experiment -- an excellent   ground for the search of Rare Radiative $B_s^0$ meson decays: A Review,"The High-Luminosity Large Hadron Collider (HL-LHC) provides unprecedented opportunities to study rare radiative decays in the flavor sector, particularly with the CMS experiment. This review focuses on the search for the challenging decay $B_s^0 \to \mu^+ \mu^- \gamma$, a flavor-changing neutral current process forbidden at tree level in the Standard Model. These decays probe Wilson coefficients C7, C9, and C10, which connect short-distance electroweak dynamics with long-distance hadronic effects. The main experimental difficulty is reconstructing low-pT photons (2-20 GeV) under extreme pile-up conditions (<mu> ~ 60). We argue that collider data naturally live on curved statistical manifolds shaped by conservation laws, detector geometry, and kinematic constraints. The Fisher-Rao information metric captures this structure, suggesting that curvature-aware analysis methods may enhance sensitivity beyond traditional approaches. We outline a framework that links collider data hierarchies, information geometry, and quantum machine learning as a pathway for future searches for rare radiative B_s^0 decays at the HL-LHC.",2025,['Alibordi Muhammad'],http://arxiv.org/abs/2509.24044v2,arxiv,,,,,,,2509.24044v2,,True
,,"Fast, accurate, and precise detector simulation with vision transformers","The speed and fidelity of detector simulations in particle physics pose compelling questions about LHC analysis and future colliders. The sparse high-dimensional data, combined with the required precision, provide a challenging task for modern generative networks. We present a comparison between solutions with different trade-offs, including accurate Conditional Flow Matching and faster coupling-based Normalising Flows. Vision Transformers allows us to emulate the energy deposition from detailed Geant4 simulations. We evaluate the networks using high-level observables, neural network classifiers, and sampling timings, showing minimum deviations from Geant4 while achieving faster generation. We use the CaloChallenge benchmark datasets for reproducibility and further development.",2025,"['Luigi Favaro', 'Andrea Giammanco', 'Claudius Krause']",http://arxiv.org/abs/2509.25169v1,arxiv,,,,,,,2509.25169v1,,True
,,Surveying the complex three Higgs doublet model with Machine Learning,"The couplings of the 125 GeV Higgs are being measured with higher precision as the Run 3 stage of LHC continues. Models with multiple Higgs doublets allow potential deviations from the SM predictions. For more than two doublets, there are five possible types of models that avoid flavor changing neutral couplings at tree level by the addition of a symmetry. We consider a softly broken Z2xZ2 three-Higgs doublet model with explicit CP violation in the scalar sector, exploring all five possible types of coupling choices and all five mass orderings of the neutral scalar bosons. The phenomenological study is performed using a Machine Learning black box optimization algorithm that efficiently searches for the possibility of large pseudoscalar Yukawa couplings. We identify the model choices that allow a purely pseudoscalar coupling in light of all recent experimental limits, including direct searches for CP-violation, thus motivating increased effort into improving the experimental precision.",2025,"['Rafael Boto', 'João A. C. Matos', 'Jorge C. Romão', 'João P. Silva']",http://arxiv.org/abs/2510.02445v1,arxiv,,,,,,,2510.02445v1,,True
,,Flavour Invariants of Multi Higgs Models,"In this work, a systematic way of analyzing the N Higgs Doublet Models flavor sector will be developed. We introduce a complete set of mixing matrices describing the rotation between certain suitably defined bases, akin to the Cabibbo-Kobayashi-Maskawa matrix, which describes the relation between the up-quark and down-quark mass bases. We point out the crucial importance played by the charged Higgs basis. It is also introduced for the first time a complete set of weak basis transformation invariant traces of flavor matrices for the general N doublets case. This will be important for studies of the renormalization group evolution in terms of relevant physical parameters.",2025,"['João C. Belas', 'João P. Silva']",http://arxiv.org/abs/2510.02465v1,arxiv,,,,,,,2510.02465v1,,False
,,Using AI on FPGAs for the CMS Overlap Muon Track Finder for the HL-LHC,"Operating the CMS Level-1 trigger under the intense conditions of the High-Luminosity Large Hadron Collider -- with approximately 63~Tb/s of input and a fixed 12.5~$\mu$s latency -- poses a demanding real-time reconstruction challenge. The CMS muon system is organized into three regions: a barrel, an endcap, and the intermediate barrel-endcap ``overlap'' region. In this overlap transition, the Overlap Muon Track Finder can be suboptimal for displaced-muon and long-lived-particle signatures. We present a first approach to a graph neural network tailored to these constraints, using GraphSAGE layers and a compact multi-layer perceptron to regress the inverse transverse momentum of muons. A PyTorch to C++ and high-level synthesis flow demonstrates feasibility, with initial results showing good agreement with simulation. Although a fully parallel implementation would exceed available field-programmable gate array resources, quantization, pruning, and multiplier reuse point the way toward a practical Phase-2 deployment.",2025,"['Pelayo Leguina', 'Santiago Folgueras', 'Andrea Cardini', 'Elena Aller']",http://arxiv.org/abs/2509.23347v1,arxiv,,,,,,,2509.23347v1,,True
,,Quantum Fisher information matrices from Rényi relative entropies,"Quantum generalizations of the Fisher information are important in quantum information science, with applications in high energy and condensed matter physics and in quantum estimation theory, machine learning, and optimization. One can derive a quantum generalization of the Fisher information matrix in a natural way as the Hessian matrix arising in a Taylor expansion of a smooth divergence. Such an approach is appealing for quantum information theorists, given the ubiquity of divergences in quantum information theory. In contrast to the classical case, there is not a unique quantum generalization of the Fisher information matrix, similar to how there is not a unique quantum generalization of the relative entropy or the R\'enyi relative entropy. In this paper, I derive information matrices arising from the log-Euclidean, $\alpha$-$z$, and geometric R\'enyi relative entropies, with the main technical tool for doing so being the method of divided differences for calculating matrix derivatives. Interestingly, for all non-negative values of the R\'enyi parameter $\alpha$, the log-Euclidean R\'enyi relative entropy leads to the Kubo-Mori information matrix, and the geometric R\'enyi relative entropy leads to the right-logarithmic derivative Fisher information matrix. Thus, the resulting information matrices obey the data-processing inequality for all non-negative values of the R\'enyi parameter $\alpha$ even though the original quantities do not. Additionally, I derive and establish basic properties of $\alpha$-$z$ information matrices resulting from the $\alpha$-$z$ R\'enyi relative entropies. For parameterized thermal states and time-evolved states, I establish formulas for their $\alpha$-$z$ information matrices and hybrid quantum-classical algorithms for estimating them, with applications in quantum Boltzmann machine learning.",2025,['Mark M. Wilde'],http://arxiv.org/abs/2510.02218v2,arxiv,,,,,,,2510.02218v2,,True
,,Development of Deep Neural Network First-Level Hardware Track Trigger   for the Belle II Experiment,"The Belle II experiment at the SuperKEKB accelerator is designed to explore physics beyond the Standard Model with unprecedented luminosity. As the beam intensity increased, the experiment faced significant challenges due to higher beam-induced background, leading to a high trigger rate and placing limitations on further luminosity increases. To address this problem, we developed trigger logic for tracking using deep neural network (DNN) technology on an FPGA for the Belle II hardware trigger system, employing high-level synthesis techniques. By leveraging drift time and hit pattern information from the Central Drift Chamber and incorporating a simplified self-attention architecture, the DNN track trigger significantly improves track reconstruction performance at the hardware level. Compared to the existing neural track trigger, our implementation reduces the total track trigger rate by 37% while improving average efficiency for the signal tracks from 96% to 98% for charged tracks with transverse momentum > 0.3 GeV. This upgrade ensures the long-term viability of the Belle II data acquisition system as luminosity continues to increase.",2025,"['Y. -X. Liu', 'T. Koga', 'H. Bae', 'Y. Yang', 'C. Kiesling', 'F. Meggendorfer', 'K. Unger', 'S. Hiesl', 'T. Forsthofer', 'A. Ishikawa', 'Y. Ahn', 'T. Ferber', 'I. Haide', 'G. Heine', 'C. -L. Hsu', 'A. Little', 'H. Nakazawa', 'M. Neu', 'L. Reuter', 'V. Savinov', 'Y. Unno', 'J. Yuan', 'Z. Xu']",http://arxiv.org/abs/2510.02762v1,arxiv,,,,,,,2510.02762v1,,True
,,Application of the holographic equations of state for modeling   experiments on heavy ion collisions,"In this paper, we propose a method for numerical modeling of the nuclear matter properties within the framework of relativistic heavy-ion collisions using a holographic equation of state. Machine learning methods were applied to address the regression and optimization issues during the calibration of the relevant parameters using the LQCD results for quark masses that approximate the physical values. Numerical simulations are performed using the iEBE-MUSIC and vHLLE-SMASH frameworks, which incorporate certain relativistic hydrodynamics solvers. We modify the code by implementing a tabulated holographic equation of state, enabling simulations of quark-gluon plasma evolution with dynamically generated initial conditions via the 3D Monte Carlo Glauber Model and SMASH. Finally, the spectra of produced hadrons are computed using a hybrid iSS+UrQMD and Hadron Sampler+SMASH approaches at the freeze-out stage.12 p",2025,"['A. V. Anufriev', 'V. N. Kovalenko']",http://arxiv.org/abs/2510.03157v1,arxiv,,,,,,,2510.03157v1,,True
,,Angular Resolution Enhancement of Electron Backscatter Diffraction   Patterns,"We present a simple 'shift-and-add' based improvement in the angular resolution of single electron backscatter diffraction (EBSD) patterns. Sub-pixel image registration is used to measure the (sub-pixel) difference in projection parameters for patterns collected within a map, and then the pattern is shifted and added together. The resultant EBSD-pattern is shown to contain more angular information than a long-exposure single pattern, via 2D Fast Fourier Transform (FFT)-based analysis. In particular, this method has the potential to enhance the scope of small compact direct electron detectors (DEDs).",2025,"['Ben Britton', 'Tianbi Zhang']",http://arxiv.org/abs/2509.23039v1,arxiv,,,,,,,2509.23039v1,,False
,,Aspects of holographic entanglement using   physics-informed-neural-networks,"We implement physics-informed-neural-networks (PINNs) to compute holographic entanglement entropy and entanglement wedge cross section. This technique allows us to compute these quantities for arbitrary shapes of the subregions in any asymptotically AdS metric. We test our computations against some known results and further demonstrate the utility of PINNs in examples, where it is not straightforward to perform such computations.",2025,"['Anirudh Deb', 'Yaman Sanghavi']",http://arxiv.org/abs/2509.25311v1,arxiv,,,,,,,2509.25311v1,,False
,,Foundation models for equation discovery in high energy physics,"Foundation models, large machine learning models trained on broad, multimodal datasets, have been gaining increasing attention in scientific applications due to their strong performance on diverse downstream tasks. Large Language Models (LLMs), a prominent instance of foundation models, have achieved remarkable success in tasks such as text and image generation. In this work, we investigate their potential for equation discovery in high energy physics, focusing on symbolic regression. We apply the LLM-SR methodology both to benchmark problems of equation recovery in lepton angular distributions and to the discovery of functional forms for angular coefficients in electroweak boson production at the Large Hadron Collider, observables of high phenomenological relevance for which no closed-form expressions are known from first principles. Our results demonstrate that LLM-SR can uncover compact, accurate, and interpretable equations across in-domain and out-of-domain kinematic regions, effectively incorporating embedded scientific knowledge and offering a promising new approach to equation discovery in high energy physics.",2025,['Manuel Morales-Alvarado'],http://arxiv.org/abs/2510.03397v1,arxiv,,,,,,,2510.03397v1,,True
,,Ultralow-Temperature Cryogenic Transmission Electron Microscopy Using a   New Helium Flow Cryostat Stage,"Advances in cryogenic electron microscopy have opened new avenues for probing quantum phenomena in correlated materials. This study reports the installation and performance of a new side-entry condenZero cryogenic cooling system for JEOL (Scanning) Transmission Electron Microscopes (S/TEM), utilizing compressed liquid helium (LHe) and designed for imaging and spectroscopy at ultra-low temperatures. The system includes an external dewar mounted on a vibration-damping stage and a pressurized, low-noise helium transfer line with a remotely controllable needle valve, ensuring stable and efficient LHe flow with minimal thermal and mechanical noise. Performance evaluation demonstrates a stable base temperature of 6.58 K measured using a Cernox bare chip sensor on the holder with temperature fluctuations within 0.04 K. Complementary in-situ electron energy-loss spectroscopy (EELS) via aluminum bulk plasmon analysis was used to measure the local specimen temperature and validate cryogenic operation during experiments. The integration of cryogenic cooling with other microscopy techniques, including electron diffraction and Lorentz TEM, was demonstrated by resolving charge density wave (CDW) transitions in NbSe2 using electron diffraction, and imaging nanometric magnetic skyrmions in MnSi via Lorentz TEM. This platform provides reliable cryogenic operation below 7 K, establishing a low-drift route for direct visualization of electronic and magnetic phase transformations in quantum materials.",2025,"['Young-Hoon Kim', 'Fehmi Sami Yasin', 'Na Yeon Kim', 'Max Birch', 'Xiuzhen Yu', 'Akiko Kikkawa', 'Yasujiro Taguchi', 'Jiaqiang Yan', 'Miaofang Chi']",http://arxiv.org/abs/2509.22804v1,arxiv,,,,,,,2509.22804v1,,False
,,Generalized Wigner theorem for non-invertible symmetries,"We establish the conditions under which a conservation law associated with a non-invertible operator may be realized as a symmetry in quantum mechanics. As established by Wigner, all quantum symmetries must be represented by either unitary or antiunitary transformations. Relinquishing an implicit assumption of invertibility, we demonstrate that the fundamental invariance of quantum transition probabilities under the application of symmetries mandates that all non-invertible symmetries may only correspond to {\it projective} unitary or antiunitary transformations, i.e., {\it partial isometries}. This extends the notion of physical states beyond conventional rays in Hilbert space to equivalence classes in an {\it extended, gauged Hilbert space}, thereby broadening the traditional understanding of symmetry transformations in quantum theory. We discuss consequences of this result and explicitly illustrate how, in simple model systems, whether symmetries be invertible or non-invertible may be inextricably related to the particular boundary conditions that are being used.",2025,"['Gerardo Ortiz', 'Chinmay Giridhar', 'Philipp Vojta', 'Andriy H. Nevidomskyy', 'Zohar Nussinov']",http://arxiv.org/abs/2509.25327v2,arxiv,,,,,,,2509.25327v2,,False
,,Simultaneous probe of the charm and bottom quark Yukawa couplings using   ttH events,"A search for the standard model Higgs boson decaying to a charm quark-antiquark pair, H $\to$ $\mathrm{c\bar{c}}$, produced in association with a top quark-antiquark pair ($\mathrm{t\bar{t}}$H) is presented. The search is performed with data from proton-proton collisions at $\sqrt{s}$ = 13 TeV, corresponding to an integrated luminosity of 138 fb$^{-1}$. Advanced machine learning techniques are employed for jet flavor identification and event classification. The Higgs boson decay to a bottom quark-antiquark pair is measured simultaneously and the observed $\mathrm{t\bar{t}}$H bb event rate relative to the standard model expectation is 0.91$\pm^{+0.26}_{-0.22}$. The observed (expected) upper limit on the product of production cross section and branching fraction $\sigma$($\mathrm{t\bar{t}}$H)$\mathcal{B}$(H $\to$ $\mathrm{c\bar{c}}$) is 0.11 (0.13$\pm^{+0.06}_{-0.04}$) pb at 95% confidence level, corresponding to 7.8 (8.7$\pm^{+4.0}_{-2.6}$) times the standard model prediction. When combined with the previous search for H $\to$ $\mathrm{c\bar{c}}$ via associated production with a W or Z boson, the observed (expected) 95% confidence interval on the Higgs-charm Yukawa coupling modifier, $\kappa_\mathrm{c}$, is $\lvert{\kappa_\mathrm{c}}\rvert$ $\lt$ 3.5 (2.7), the most stringent constraint to date.",2025,['CMS Collaboration'],http://arxiv.org/abs/2509.22535v1,arxiv,,,,,,,2509.22535v1,,True
,,"Rings of Light, Speed of AI: YOLO for Cherenkov Reconstruction","Cherenkov rings play a crucial role in identifying charged particles in high-energy physics (HEP) experiments. Most Cherenkov ring pattern reconstruction algorithms currently used in HEP experiments rely on a likelihood fit to the photo-detector response, which often consumes a significant portion of the computing budget for event reconstruction. We present a novel approach to Cherenkov ring reconstruction using YOLO, a computer vision algorithm capable of real-time object identification with a single pass through a neural network. We obtain a reconstruction efficiency above 95% and a pion misidentification rate below 5% across a wide momentum range for all particle species.",2025,"['Martino Borsato', 'Giovanni Laganà', 'Maurizio Martinelli']",http://arxiv.org/abs/2509.26273v1,arxiv,,,,,,,2509.26273v1,,True
,,Physics Informed Neural Networks for design optimisation of diamond   particle detectors for charged particle fast-tracking at high luminosity   hadron colliders,"Future high-luminosity hadron colliders demand tracking detectors with extreme radiation tolerance, high spatial precision, and sub-nanosecond timing. 3D diamond pixel sensors offer these capabilities due to diamond's radiation hardness and high carrier mobility. Conductive electrodes, produced via femtosecond IR laser pulses, exhibit high resistivity that delays signal propagation. This effect necessitates extending the classical Ramo-Shockley weighting potential formalism. We model the phenomenon through a 3rd-order, 3+1D PDE derived as a quasi-stationary approximation of Maxwell's equations. The PDE is solved numerically and coupled with charge transport simulations for realistic 3D sensor geometries. A Mixture-of-Experts Physics-Informed Neural Network, trained on Spectral Method data, provides a meshless solver to assess timing degradation from electrode resistance.",2025,"['Alessandro Bombini', 'Alessandro Rosa', 'Clarissa Buti', 'Giovanni Passaleva', 'Lucio Anderlini']",http://arxiv.org/abs/2509.21123v1,arxiv,,,,,,,2509.21123v1,,True
,,Graph Neural Network Acceleration on FPGAs for Fast Inference in Future   Muon Triggers at HL-LHC,"The High-Luminosity LHC (HL-LHC) will reach luminosities up to 7 times higher than the previous run, yielding denser events and larger occupancies. Next generation trigger algorithms must retain reliable selection within a strict latency budget. This work explores machine-learning approaches for future muon triggers, using the ATLAS Muon Spectrometer as a benchmark. A Convolutional Neural Network (CNN) is used as a reference, while a Graph Neural Network (GNN) is introduced as a natural model for sparse detector data. Preliminary single-track studies show that GNNs achieve high efficiency with compact architectures, an encouraging result in view of FPGA deployment.",2025,"['Martino Errico', 'Davide Fiacco', 'Stefano Giagu', 'Giuliano Gustavino', 'Valerio Ippolito', 'Graziella Russo']",http://arxiv.org/abs/2509.26419v1,arxiv,,,,,,,2509.26419v1,,True
,,Energy-Energy Flow Networks,"Jet substructure provides one of the most exciting new approaches for searching for physics in and beyond the Standard Model at the Large Hadron Collider. Modern jet substructure searches are often performed with Neural Network (NN) taggers which study the jets' radiation distributions in great detail, far beyond what is theoretically described by parton shower generators. While this represents a great opportunity, as NNs look deeper into the structure of jets they become increasingly sensitive both to perturbative and non-perturbative theoretical uncertainties. It is therefore important to be able to control which aspects of both regimes the networks focus on, and to develop techniques for quantifying these uncertainties. In this paper we take two steps in this direction: First, we introduce EnFNs, a generalization of the Energy Flow Networks (EFNs) which directly probes higher point correlations in jets, as motivated by recent advances in the study of energy correlators. Second, we introduce a number of techniques to quantify and visualize their robustness to non-perturbative corrections. We highlight the importance of such considerations in a toy study incorporating systematics into a search, and maximizing for the network's discovery significance, as opposed to absolute tagging performance. We hope this study continues the interest in understanding the role QCD systematics play in Machine Learning applications and opens the door to a better interplay between theory and experiment in HEP.",2025,"['Arianna Garcia Caffaro', 'Ian Moult', 'Chase Shimmin']",http://arxiv.org/abs/2510.06314v1,arxiv,,,,,,,2510.06314v1,,True
,,Bioinspired Tapered-Spring Turbulence Sensor for Underwater Flow   Detection,"This paper presents a bio-inspired underwater whisker sensor for robust hydrodynamic disturbance detection and efficient signal analysis based on Physical Reservoir Computing (PRC). The design uses a tapered nylon spring with embedded accelerometers to achieve spatially distributed vibration sensing and frequency separation along the whisker. Towing-tank experiments and computational fluid dynamics simulations confirmed that the whisker effectively distinguishes vortex regimes across different fin angles and maintains Strouhal scaling with flow velocity, where higher speeds increase vibration intensity without affecting the dominant frequencies. Frequency-domain analysis, Shannon entropy, and machine learning further validated the sensing performance: vortex shedding frequencies were identified with less than 10\% error, entropy captured the transition from coherent vortex streets to turbulence, and logistic regression achieved 86.0\% classification accuracy with millisecond-level inference. These results demonstrate that structurally encoded whisker sensing provides a scalable and real-time solution for underwater perception, wake tracking, and turbulence-aware navigation in autonomous marine robots.",2025,"['Xiao Jin', 'Zhenhua Yu', 'Thrishantha Nanayakkara']",http://arxiv.org/abs/2510.07348v1,arxiv,,,,,,,2510.07348v1,,True
,,Kerr-Schild transformation of the Benenti-Francaviglia metric,"The Benenti-Francaviglia (BF) family of metrics provides the most general form of a spacetime metric that admits two mutually commuting Killing vectors and an irreducible Killing tensor. The geodesic equations for the BF family are thus completely integrable by separation of variables. Within this broad class, we explore the Kerr-Schild transformation of a degenerate subclass distinguished by the existence of a shear-free null geodesic congruence. By requiring the deformed metric to preserve the Killing symmetry and circularity, we demonstrate that the deformed metric again falls into the degenerate BF family, modulo the replacement of a single structure function. We apply the present algorithm to ${\cal N}=2$ gauged supergravity and obtain a dyonic generalization of the Chong-Cveti\v{c}-L\""u-Pope rotating black hole solution, by taking the background metric to be a solution of the Einstein-scalar gravity. The present prescription extends to five dimensions, provided that the constant of geodesic motion associated with the extra Killing direction vanishes. The same reasoning applies to the case where the background degenerate BF metric is distorted in a (non)conformal manner. Our formalism offers a unified perspective on the relation between seed and deformed metrics in the Kerr-Schild construction.",2025,"['Masato Nozawa', 'Takashi Torii']",http://arxiv.org/abs/2510.06561v1,arxiv,,,,,,,2510.06561v1,,False
,,Sensor Co-design for $\textit{smartpixels}$,"Pixel tracking detectors at upcoming collider experiments will see unprecedented charged-particle densities. Real-time data reduction on the detector will enable higher granularity and faster readout, possibly enabling the use of the pixel detector in the first level of the trigger for a hadron collider. This data reduction can be accomplished with a neural network (NN) in the readout chip bonded with the sensor that recognizes and rejects tracks with low transverse momentum (p$_T$) based on the geometrical shape of the charge deposition (``cluster''). To design a viable detector for deployment at an experiment, the dependence of the NN as a function of the sensor geometry, external magnetic field, and irradiation must be understood. In this paper, we present first studies of the efficiency and data reduction for planar pixel sensors exploring these parameters. A smaller sensor pitch in the bending direction improves the p$_T$ discrimination, but a larger pitch can be partially compensated with detector depth. An external magnetic field parallel to the sensor plane induces Lorentz drift of the electron-hole pairs produced by the charged particle, broadening the cluster and improving the network performance. The absence of the external field diminishes the background rejection compared to the baseline by $\mathcal{O}$(10%). Any accumulated radiation damage also changes the cluster shape, reducing the signal efficiency compared to the baseline by $\sim$ 30 - 60%, but nearly all of the performance can be recovered through retraining of the network and updating the weights. Finally, the impact of noise was investigated, and retraining the network on noise-injected datasets was found to maintain performance within 6% of the baseline network trained and evaluated on noiseless data.",2025,"['Danush Shekar', 'Ben Weiss', 'Morris Swartz', 'Corrinne Mills', 'Jennet Dickinson', 'Lindsey Gray', 'David Jiang', 'Mohammad Abrar Wadud', 'Daniel Abadjiev', 'Anthony Badea', 'Douglas Berry', 'Alec Cauper', 'Arghya Ranjan Das', 'Giuseppe Di Guglielmo', 'Karri Folan DiPetrillo', 'Farah Fahim', 'Rachel Kovach Fuentes', 'Abhijith Gandrakota', 'James Hirschauer', 'Eliza Howard', 'Shiqi Kuang', 'Carissa Kumar', 'Ron Lipton', 'Mia Liu', 'Petar Maksimovic', 'Nick Manganelli', 'Mark S Neubauer', 'Aidan Nicholas', 'Emily Pan', 'Benjamin Parpillon', 'Jannicke Pearkes', 'Gauri Pradhan', 'Shruti R Kulkarni', 'Ricardo Silvestre', 'Chinar Syal', 'Nhan Tran', 'Amit Trivedi', 'Keith Ulmer', 'Manuel Blanco Valentin', 'Dahai Wen', 'Jieun Yoo', 'Eric You', 'Aaron Young']",http://arxiv.org/abs/2510.06588v1,arxiv,,,,,,,2510.06588v1,,True
,,Latent Representation Learning in Heavy-Ion Collisions with MaskPoint   Transformer,"A central challenge in high-energy nuclear physics is to extract informative features from the high-dimensional final-state data of heavy-ion collisions (HIC) in order to enable reliable downstream analyses. Traditional approaches often rely on selected observables, which may miss subtle but physically relevant structures in the data. To address this, we introduce a Transformer-based autoencoder trained with a two-stage paradigm: self-supervised pre-training followed by supervised fine-tuning. The pretrained encoder learns latent representations directly from unlabeled HIC data, providing a compact and information-rich feature space that can be adapted to diverse physics tasks. As a case study, we apply the method to distinguish between large and small collision systems, where it achieves significantly higher classification accuracy than PointNet. Principal component analysis and SHAP interpretation further demonstrate that the autoencoder captures complex nonlinear correlations beyond individual observables, yielding features with strong discriminative and explanatory power. These results establish our two-stage framework as a general and robust foundation for feature learning in HIC, opening the door to more powerful analyses of quark--gluon plasma properties and other emergent phenomena. The implementation is publicly available at https://github.com/Giovanni-Sforza/MaskPoint-AMPT.",2025,"['Jing-Zong Zhang', 'Shuang Guo', 'Li-Lin Zhu', 'Lingxiao Wang', 'Guo-Liang Ma']",http://arxiv.org/abs/2510.06691v1,arxiv,,,,,,,2510.06691v1,,True
,,Low-noise Fourier Transform Spectroscopy Enabled by Superconducting   On-Chip Filterbank Spectrometers,"Historically employed spectroscopic architectures used for large field of view mapping spectroscopy in millimetere and sub-millimetre astronomy suffer from significant drawbacks. On-chip filterbank spectrometers are a promising technology in this respect; however, they must overcome an orders-of-magnitude increase in detector counts, efficiency loss due to dielectric properties, and stringent fabrication tolerances that currently limit scaling to resolutions of order 1000 over a large array. We propose coupling a medium-resolution Fourier transform spectrometer to a low-resolution filterbank spectrometer focal plane, which serves as a post-dispersion element. In this arrangement, medium resolution imaging spectroscopy is provided by the Fourier transform spectrometer, while the low resolution filterbank spectrometer serves to decrease the photon noise inherent in typical broadband Fourier transform spectrometer measurements by over an order of magnitude. This is achieved while maintaining the excellent imaging advantages of both architectures. We present predicted mapping speeds for a filterbank-dispersed Fourier transform spectrometer from a ground-based site and a balloon-borne platform. We also demonstrate the potential that an instrument of this type has for an R~1000 line intensity mapping experiment using the James Clerk Maxwell Telescope as an example platform. We demonstrate that a filterbank-dispersed Fourier transform spectrometer would be capable of R~1000 measurements of CO power spectra with a signal-to-noise ratio of 10--100 with surveys of $10^5$--$10^6$ spectrometer hours.",2025,"['Chris S. Benson', 'Peter S. Barry', 'Patrick Ashworth', 'Harry Gordon-Moys', 'Kirit S. Karkare', 'Izaak Morris', 'Gethin Robson']",http://arxiv.org/abs/2510.06771v1,arxiv,,,,,,,2510.06771v1,,False
,,Non-linear sigma model in string field theory,"We revisit the non-linear sigma model approach to string theory with the closed superstring field theory. We construct the string field theory around the non-linear sigma model background with the patch-by-patch description. We show that our string field theory action is invariant under the gauge transformation and solves the BV master equation, thereby providing a tool to study quantum gravitational effects in curved backgrounds in small $\alpha'$ and $g_s$ approximation. We illustrate how to use our results to study curved backgrounds in $\alpha'$ expansion by studying Calabi-Yau compactification in $\alpha'$ expansion. We draw connections between Tseytlin's approach to the non-linear sigma model and the string field theoretic approach. We comment on future directions.",2025,"['Alexander Frenkel', 'Manki Kim']",http://arxiv.org/abs/2509.20527v1,arxiv,,,,,,,2509.20527v1,,False
,,Polarized Neutral and Charged Current Semi-Inclusive Deep-Inelastic   Scattering at NNLO in QCD,"The semi-inclusive production of identified hadrons in deeply inelastic lepton scattering on polarized nucleons allows to probe the spin structure of the nucleon target in a more detailed level than through fully inclusive processes. We compute the NNLO QCD corrections to longitudinally polarized semi-inclusive deep inelastic processes mediated by electroweak neutral and charged currents. We present the first calculation of polarized electroweak structure functions in the Larin scheme up to NNLO. Additionally, we reformulate the finite scheme transformation to the $\overline{\textrm{MS}}$ scheme in a quark flavour basis and identify issues in its assignment to partonic channels in previous calculations. Using our results we perform a detailed phenomenological study of polarized cross sections and of single and double spin asymmetries. We observe large electroweak effects, which need to be included in precision studies of polarized observables.",2025,"['Leonardo Bonino', 'Thomas Gehrmann', 'Markus Löchner', 'Kay Schönwald', 'Giovanni Stagnitto']",http://arxiv.org/abs/2510.00100v1,arxiv,,,,,,,2510.00100v1,,False
,,Analytic Langlands correspondence from SoV,"The analytic Langlands correspondence proposed by Etingof, Frenkel and Kazhdan describes the solution to the spectral problems naturally arising in the quantisation of the Hitchin integrable systems in terms of real opers, certain second order differential operators on a Riemann surface having real monodromy. We prove this correspondence in the cases associated to the group $\mathrm{PSL}(2,\mathbb{C})$, and Riemann surfaces of genus zero with a number of punctures larger than three. A crucial ingredient is a unitary integral transformation mapping products of solutions to the ordinary differential equation associated to a real oper to eigenfunctions of the quantised Hitchin Hamiltonians. This allows us to construct joint eigenfunctions of Hecke operators and Hitchin Hamiltonians from real opers.",2025,"['Federico Ambrosino', 'Jörg Teschner']",http://arxiv.org/abs/2510.06991v1,arxiv,,,,,,,2510.06991v1,,False
,,Geometric Building Blocks of Effective Field Theory Amplitudes,"On-shell amplitudes are invariant under field redefinitions. Nonderivative field redefinitions have a natural interpretation as coordinate transformations on the target manifold. General field redefinitions, which may involve derivatives, can be viewed as coordinate transformations on the field configuration manifold. We present a unified perspective for the geometry of both the target manifold and the field configuration manifold for scalar effective field theories. In both cases, we identify vertices that can be used to build the tree-level amplitudes, with the property that they transform covariantly in the vacuum and on-shell limits. We identify a choice of metric on the field configuration manifold, for which amplitude expressions on the target manifold can be easily reproduced from their counterparts on the field configuration manifold. This clarifies the relation between the well-established framework of field space geometry and recent proposals for functional geometry.",2025,"['Timothy Cohen', 'Xu-Xiang Li', 'Zhengkang Zhang']",http://arxiv.org/abs/2509.20449v1,arxiv,,,,,,,2509.20449v1,,False
,,Renormalization of Interacting Random Graph Models,"Random graphs offer a useful mathematical representation of a variety of real world complex networks. Exponential random graphs, for example, are particularly suited towards generating random graphs constrained to have specified statistical moments. In this investigation, we elaborate on a generalization of the former where link probabilities are conditioned on the appearance of other links, corresponding to the introduction of interactions in an effective generalized statistical mechanical formalism. When restricted to the simplest non-trivial case of pairwise interactions, one can derive a closed form renormalization group transformation for maximum coordination number two on the corresponding line graph. Higher coordination numbers do not admit exact closed form renormalization group transformations, a feature that paraphrases the usual absence of exact transformations in two or more dimensional lattice systems. We introduce disorder and study the induced renormalization group flow on its probability assignments, highlighting its formal equivalence to time reversed anisotropic drift-diffusion on the statistical manifold associated with the effective Hamiltonian. We discuss the implications of our findings, stressing the long wavelength irrelevance of certain classes of pair-wise conditioning on random graphs, and conclude with possible applications. These include modeling the scaling behavior of preferential effects on social networks, opinion dynamics, and reinforcement effects on neural networks, as well as how our findings offer a systematic framework to deal with data limitations in inference and reconstruction problems.",2025,"['Alessio Catanzaro', 'Diego Garlaschelli', 'Subodh P. Patil']",http://arxiv.org/abs/2510.07186v1,arxiv,,,,,,,2510.07186v1,,True
,,Localized states of BFSS super quantum mechanics,"We analyze the recently discovered localized and non-uniform phases of the Banks-Fischler-Shenker-Susskind (BFSS) matrix quantum mechanics. Building on [1], we provide first-principles derivations of their properties and extend the results with new analytic and numerical insights. We show that strongly coupled BFSS dynamics emerge from a specific Carrollian transformation of 11-dimensional supergravity, which we justify in detail. In this framework, the uniform BFSS phase corresponds to a black string in a $pp$-wave background. We demonstrate that this background is unstable to a Gregory-Laflamme instability and, for the first time, compute the associated growth rate. The instability gives rise to non-uniform and localized phases that dominate the microcanonical ensemble in certain low-energy regimes, with the localized phase also prevailing in the canonical ensemble at low temperatures. We identify the corresponding first- and second-order phase transitions and derive analytic formulas for the thermodynamics of the localized phase, accurate to better than $0.3\%$ against numerical results.",2025,"['Oscar J. C. Dias', 'Jorge E. Santos']",http://arxiv.org/abs/2510.07379v1,arxiv,,,,,,,2510.07379v1,,False
,,Spinning Mellin amplitudes,"We propose a definition of Mellin amplitudes for conformal correlators involving arbitrary spinning operators in tensor representations of the Lorentz group. These representations cover all bosonic local operators. Our strategy is to perform discrete Mellin transforms on all scalar products involving polarization vectors, so that each polarization vector can be interpreted as the position of a fictitious scalar operator. We establish the general pole structures and factorization properties of these spinning Mellin amplitudes. We also provide a systematic algorithm to derive factorization formulas with arbitrary spinning exchanges, yielding new explicit results up to spin-4. To illustrate the practicality of our formalism, we bootstrap the 3- and 4-point current correlators in a 4d $\mathcal{N}=2$ superconformal field theory, which are dual to gluon scattering amplitudes in $\mathrm{AdS}_5 \times \mathrm{S}^3$. The results agree with the snowflake channel of 6- and 8-point scalar supergluon amplitudes in the literature.",2025,"['Zhongjie Huang', 'Yichao Tang']",http://arxiv.org/abs/2510.07388v1,arxiv,,,,,,,2510.07388v1,,False
,,On the consistent disformal couplings to fermions,"Disformal couplings to fermions lead to a unique derivative coupling to the axial fermionic current, which contains higher derivatives in general. We derive general conditions on consistent disformal couplings by requiring the absence of higher time derivatives, as they typically lead to ghost degrees of freedom. For a two-scalar field disformal transformation, we show that the consistent disformal coupling must have a degenerate field space metric. This allows us to explore consistent, new two-scalar field modified gravity models. We show that the transformation of the Einstein-Hilbert action leads to two-field Horndeski or two-field DHOST theories. Our formalism also applies to disformal transformations with higher derivatives. We derive the consistent subclasses of disformal transformations that include second derivatives of a scalar field and first derivatives of a vector field that lead to generalized U-DHOST and degenerate beyond generalized Proca theories.",2025,"['Guillem Domènech', 'Alexander Ganz', 'Apostolos Tsabodimos']",http://arxiv.org/abs/2510.07419v1,arxiv,,,,,,,2510.07419v1,,False
,,Boosted decision tree reweighting of simulated neutrino interactions for   $O(1)$ GeV neutrino cross-section measurements,"This paper illustrates a generic method for multi-dimensional reweighting of $O(1)$ GeV neutrino interaction Monte Carlo samples. The reweighting is based on a Boosted Decision Tree algorithm trained on high-dimensional space in detector final state observables. This enables one generator's events to be reweighted so that its reconstructed particle content and kinematics distributions, as well as detector efficiency, match those of a target model. The approach establishes an efficient way to reuse legacy Monte Carlo data, avoiding re-generation. As an example, we test its use in a measurement of transverse kinematic imbalance of the $\mu^-$ and proton in charged-current quasielastic like $\nu_\mu$ events from the MINERvA experiment.",2025,"['Z. Lin', 'S. Akhter', 'Z. Ahmad Dar', 'N. S. Alex', 'M. Betancourt', 'S. Boyd', 'H. Budd', 'G. Caceres', 'G. A. Díaz', 'J. Felix', 'L. Fields', 'A. M. Gago', 'P. K. Gaur', 'S. M. Gilligan', 'R. Gran', 'D. A. Harris', 'A. L. Hart', 'J. Kleykamp', 'A. Klustová', 'D. Last', 'A. Lozano', 'X. -G. Lu', 'S. Manly', 'W. A. Mann', 'K. S. McFarland', 'O. Moreno', 'J. K. Nelson', 'V. Paolone', 'G. N. Perdue', 'C. Pernas', 'M. A. Ramírez', 'N. Roy', 'D. Ruterbories', 'H. Schellman', 'C. J. Solano Salinas', 'D. S. Correia', 'M. Sultana', 'N. H. Vaughan', 'A. V. Waldron', 'B. Yaeggy', 'L. Zazueta']",http://arxiv.org/abs/2510.07463v1,arxiv,,,,,,,2510.07463v1,,True
,,Apparent Lorentz violation from disformally coupled ultralight dark   matter,"We study the impact of general disformal metric transformations on fermions, which shift the gravitational metric by an additional rank-2 tensor. This tensor can in principle be constructed from scalar-field gradients, vector fields, or field-strength contractions. We show this transformation results in the conventional Dirac action being modified by additional kinetic and axial-current couplings that are quadratic in the shifted field. When the field sourcing the metric shift takes on a non-trivial background value, apparent Lorentz-violating effects can result, which we identify as terms in an effective field theory. Assuming the well-motivated cases of scalar and vector ultralight dark matter, we demonstrate that experimental tests of rotation and boost violation imply constraints on the additional kinetic coupling. Even under conservative assumptions, the constraints for vector ultralight dark matter are extremely stringent.",2025,"['Guillem Domènech', 'Apostolos Tsabodimos', 'Nathaniel Sherrill', 'Alexander Ganz', 'Fiona Kirk']",http://arxiv.org/abs/2510.07490v1,arxiv,,,,,,,2510.07490v1,,False
,,Efficient Radiofrequency Sensing with Fluorescence Encoding,"Optically-active spin qubits have emerged as powerful quantum sensors capable of nanoscale magnetometry, yet conventional coherent sensing approaches are ultimately limited by the coherence time of the sensor, typically precluding detection in the sub-MHz regime. We present a broadly applicable fluorescence-encoding method that circumvents coherence-time constraints by transducing time-varying magnetic fields directly into modulated fluorescence signals. Using nitrogen-vacancy centers in diamond as a model system, we demonstrate shot-noise-limited sensitivity for AC magnetic fields spanning near-DC to MHz frequencies, with detection bandwidth tunable via optical excitation power. The technique captures complete spectral information in a single measurement, eliminating the need for point-by-point frequency scanning, and allows phase-sensitive multi-frequency detection with Hz-level resolution. This approach transforms quantum sensors into atomic-scale spectrum analyzers, with immediate applications for low-frequency RF communication, zero-field NMR, and bioelectronic sensing. Our approach is broadly applicable to the expanding class of optically-active spin qubits, including molecular systems and fluorescent proteins, opening new sensing regimes previously inaccessible to coherent techniques",2025,"['Nicole Voce', 'Paul Stevenson']",http://arxiv.org/abs/2510.07510v1,arxiv,,,,,,,2510.07510v1,,False
,,Enhancing the Sensitivity for Triple Higgs Boson Searches with Deep   Learning Techniques,"Using two benchmark models containing extended scalar sectors beyond the Standard Model, we study deep learning techniques to enhance the sensitivity of resonant triple Higgs boson searches in the fully hadronic $6b$ channel, which suffers from the combinatorial challenge of reconstructing the Higgs bosons correctly from the multiple $b$-jets. More specifically, we employ the framework of Symmetry Preserving Attention Network (\textsc{Spa-Net}), which takes into account the permutational symmetry when a correct pairing of $b$-jets is achieved, to tackle both jet pairing and event classification. Significantly improved efficiency is achieved in signal and background discrimination. When comparing with the conventional Dense Neural Networks, \textsc{Spa-Net} results in up to 40\% more stringent limits on resonant production cross-sections. These results highlight the potential of using advanced machine learning techniques to significantly improve the sensitivity of triple Higgs boson searches in the fully hadronic channel.",2025,"['Cheng-Wei Chiang', 'Feng-Yang Hsieh', 'Shih-Chieh Hsu', 'Ian Low', 'Zhi-Zhong Li']",http://arxiv.org/abs/2510.01672v1,arxiv,,,,,,,2510.01672v1,,True
,,Charged Black-Hole Binary Evolution at Second Post-Newtonian Order,"We study the dynamics of electrically charged black-hole binaries and their gravitational-wave emission during the inspiral phase. Within the post-Newtonian framework, we derive the conservative and dissipative dynamics up to second order (2PN), combining Effective Field Theory and classical methods. We compute the NNLO conservative Lagrangian, LO dissipative effects in harmonic and Lorenz gauges, and provide the equations of motion, center-of-mass transformations, and the Lagrangian/Hamiltonian in ADM-type coordinates. We also obtain gauge-invariant expressions for the binding energy, periastron advance in quasi-circular orbits, and the scattering angle in unbound orbits. Our results extend previous analyses and are fully consistent with recent post-Minkowskian findings.",2025,"['Andrea Placidi', 'Elisa Grilli', 'Marta Orselli', 'Matteo Pegorin', 'Nicola Bartolo', 'Pierpaolo Mastrolia']",http://arxiv.org/abs/2509.20432v2,arxiv,,,,,,,2509.20432v2,,False
,,Spinning Boundary Correlators from (A)dS$_4$ Twistors,"We develop a twistor-space framework to compute boundary correlators via a boundary limit of nested Penrose transforms in (A)dS$_4$. Starting from correlators of (anti-)self-dual bulk fields, the boundary limit reproduces the correlators of the dual conserved currents; we demonstrate this explicitly for two- and three-point functions. The two-point correlator is rendered finite by working in Euclidean signature. At three points, we obtain compact rational twistor-space representatives obeying a double-copy relation, thereby clarifying the twistor-space origin of the results in Baumann et al. 2024. We further extend the analysis to non-conserved currents with integer conformal dimension, dual to massive bulk fields, as well as to the free scalar.",2025,"['Mariana Carrillo González', 'Théo Keseman']",http://arxiv.org/abs/2510.00096v1,arxiv,,,,,,,2510.00096v1,,False
,,"Complex Lies, Real Physics: The Role of Algebra Complexification","In physics, Lie groups represent the algebraic structure that describes symmetry transformations of a given system. Then, the descending Lie algebra of those groups are necessary real. In most cases, the complexification of those Lie algebra is necessary in order to derive irreductible representations of the Lie algebra and subsequently of the symmetry group. In this paper, we give a precise definition of the concept and prove step by step an important result $$\left(\mathfrak{g}^\mathbb{R}\right)_\mathbb{C} \simeq \mathfrak{g} \times \bar{\mathfrak{g}}. $$ This result is used to determine the irreductible representations of the proper Lorentz group and thus the physical objects admissible when this symmetry is present. It is shown that finite representations of the proper Lorentz group are characterized by pairs of half-integers $(j_1,j_2)$, which determine unambiguously the physical object associated to the given representation. For example, the representation $(0,0)$ of dimension $1$ is called the scalar representation, it corresponds to the Higgs field, and $(\frac{1}{2},0) \oplus (0,\frac{1}{2})$ of dimension $4$ is called the Dirac spinor representation, it corresponds to matter particle called fermions. This means that the mathematical group structure determines the material content of the universe following this algebraic structure.",2025,"['Tanguy Marsault', 'Laurent Schoeffel']",http://arxiv.org/abs/2509.20929v2,arxiv,,,,,,,2509.20929v2,,False
,,Advancing the CMS Level-1 Trigger: Jet Tagging with DeepSets at the   HL-LHC,"At the High Luminosity LHC, selecting important physics processes such as (di-) Higgs production will be a high priority. The Phase-2 Upgrade of the CMS Level-1 Trigger will reconstruct particle candidates and use pileup mitigation for the 200 simultaneous proton-proton interactions. A fast cone algorithm will reconstruct jets from these particles, providing access to jet constituents for the first time. We introduce a new multi-class jet tagger with a small, quantized DeepSets neural network. The tagger, trained on a mix of simulated CMS events, predicts various hadronic and leptonic classes. We present the tagger, its performance, and its improvements for triggering on (di-) Higgs events.",2025,"['Stella Schaefer', 'Christopher Brown', 'Duc Hoang', 'Sioni Summers', 'Sebastian Wuchterl']",http://arxiv.org/abs/2509.24371v1,arxiv,,,,,,,2509.24371v1,,True
,,Overlap-aware segmentation for topological reconstruction of obscured   objects,"The separation of overlapping objects presents a significant challenge in scientific imaging. While deep learning segmentation-regression algorithms can predict pixel-wise intensities, they typically treat all regions equally rather than prioritizing overlap regions where attribution is most ambiguous. Recent advances in instance segmentation show that weighting regions of pixel overlap in training can improve segmentation boundary predictions in regions of overlap, but this idea has not yet been extended to segmentation regression. We address this with Overlap-Aware Segmentation of ImageS (OASIS): a new segmentation-regression framework with a weighted loss function designed to prioritize regions of object-overlap during training, enabling extraction of pixel intensities and topological features from heavily obscured objects. We demonstrate OASIS in the context of the MIGDAL experiment, which aims to directly image the Migdal effect--a rare process where electron emission is induced by nuclear scattering--in a low-pressure optical time projection chamber. This setting poses an extreme test case, as the target for reconstruction is a faint electron recoil track which is often heavily-buried within the orders-of-magnitude brighter nuclear recoil track. Compared to unweighted training, OASIS improves median intensity reconstruction errors from -32% to -14% for low-energy electron tracks (4-5 keV) and improves topological intersection-over-union scores from 0.828 to 0.855. These performance gains demonstrate OASIS's ability to recover obscured signals in overlap-dominated regions. The framework provides a generalizable methodology for scientific imaging where pixels represent physical quantities and overlap obscures features of interest. All code is openly available to facilitate cross-domain adoption.",2025,"['J. Schueler', 'H. M. Araújo', 'S. N. Balashov', 'J. E. Borg', 'C. Brew', 'F. M. Brunbauer', 'C. Cazzaniga', 'A. Cottle', 'D. Edgeman', 'C. D. Frost', 'F. Garcia', 'D. Hunt', 'M. Kastriotou', 'P. Knights', 'H. Kraus', 'A. Lindote', 'M. Lisowska', 'D. Loomba', 'E. Lopez Asamar', 'P. A. Majewski', 'T. Marley', 'C. McCabe', 'L. Millins', 'R. Nandakumar', 'T. Neep', 'F. Neves', 'K. Nikolopoulos', 'E. Oliveri', 'A. Roy', 'T. J. Sumner', 'E. Tilly', 'W. Thompson', 'M. A. Vogiatzi']",http://arxiv.org/abs/2510.06194v1,arxiv,,,,,,,2510.06194v1,,True
,,TrackCore-F: Deploying Transformer-Based Subatomic Particle Tracking on   FPGAs,"The Transformer Machine Learning (ML) architecture has been gaining considerable momentum in recent years. In particular, computational High-Energy Physics tasks such as jet tagging and particle track reconstruction (tracking), have either achieved proper solutions, or reached considerable milestones using Transformers. On the other hand, the use of specialised hardware accelerators, especially FPGAs, is an effective method to achieve online, or pseudo-online latencies. The development and integration of Transformer-based ML to FPGAs is still ongoing and the support from current tools is very limited to non-existent. Additionally, FPGA resources present a significant constraint. Considering the model size alone, while smaller models can be deployed directly, larger models are to be partitioned in a meaningful and ideally, automated way. We aim to develop methodologies and tools for monolithic, or partitioned Transformer synthesis, specifically targeting inference. Our primary use-case involves two machine learning model designs for tracking, derived from the TrackFormers project. We elaborate our development approach, present preliminary results, and provide comparisons.",2025,"['Arjan Blankestijn', 'Uraz Odyurt', 'Amirreza Yousefzadeh']",http://arxiv.org/abs/2509.26335v1,arxiv,,,,,,,2509.26335v1,,True
,,Time-dependent 3D oscillator with Coulomb interaction: an alternative   approach for analyzing quark-antiquark systems,"In this work, the dynamics of quark-antiquark pair systems is investigated by modelling them as general time-dependent 3D oscillators perturbed by a Coulomb potential. Solving this model enables the prediction of key mesonic properties such as the probability density, energy spectra, and quadrature uncertainties, offering theoretical insights into the confinement of quarks via gluon-mediated strong interactions. To tackle the mathematical difficulty raised by the time dependence of parameters in the system, special mathematical techniques, such as the invariant operator method, unitary transformation method, and the Nikiforov-Uvarov functional analysis (NUFA) are used. The wave functions of the system, derived using these mathematical techniques, are expressed analytically in terms of the Gauss hypergeometric function whose mathematical properties are well characterized. Our results provide the quantum mechanical framework of quark-antiquark systems which are essential for exploring the non-perturbative aspects of QCD. In addition, the underlying mathematical structure may serve as a foundation for addressing broader challenges in particle physics, including the origin of mass and its connection to the Higgs mechanism.",2025,"['Jeong Ryeol Choi', 'Salim Medjber', 'Salah Menouar', 'Ramazan Sever']",http://arxiv.org/abs/2510.04541v1,arxiv,,,,,,,2510.04541v1,,False
,,Subleading Twist-3 Gluon Generalized Parton Distributions in the   Light-Front Model,"We present a calculation of the twist-3 generalized parton distributions (GPDs) for gluons in the proton. Our analysis is performed within a light-front constituent model where the proton is treated as a two-body state of a spin-1 gluon and a spin-1/2 spectator system. The requisite light-front wave functions are derived from the soft-wall AdS/QCD correspondence. We compute the complete set of twist-3 gluon GPDs over a broad kinematic range. The corresponding distributions in impact parameter space are obtained via Fourier transform, revealing the transverse spatial distribution of gluons. Furthermore, we evaluate the contribution of these GPDs to the gluon kinetic orbital angular momentum (OAM) and compare our findings with other theoretical predictions.",2025,"['Parashmani Thakuria', 'Madhurjya Lalung', 'Jayanta Kumar Sarma']",http://arxiv.org/abs/2510.04513v1,arxiv,,,,,,,2510.04513v1,,False
,,Approximate Gaussianity Beyond Initialisation in Neural Networks,"Ensembles of neural network weight matrices are studied through the training process for the MNIST classification problem, testing the efficacy of matrix models for representing their distributions, under assumptions of Gaussianity and permutation-symmetry. The general 13-parameter permutation invariant Gaussian matrix models are found to be effective models for the correlated Gaussianity in the weight matrices, beyond the range of applicability of the simple Gaussian with independent identically distributed matrix variables, and notably well beyond the initialisation step. The representation theoretic model parameters, and the graph-theoretic characterisation of the permutation invariant matrix observables give an interpretable framework for the best-fit model and for small departures from Gaussianity. Additionally, the Wasserstein distance is calculated for this class of models and used to quantify the movement of the distributions over training. Throughout the work, the effects of varied initialisation regimes, regularisation, layer depth, and layer width are tested for this formalism, identifying limits where particular departures from Gaussianity are enhanced and how more general, yet still highly-interpretable, models can be developed.",2025,"['Edward Hirst', 'Sanjaye Ramgoolam']",http://arxiv.org/abs/2510.05218v1,arxiv,,,,,,,2510.05218v1,,True
,,Baryons as linked vortices in QCD matter with isospin asymmetry,"We investigate a baryonic structure in low-energy QCD via a model-independent way using the chiral perturbation theory at the leading order, in the presence of the baryon chemical potential $\mu_B$, the isospin chemical potential $\mu_I$, and the electromagnetic coupling. For such a scenario in the chiral limit, it has been known that the neutral pion winds like in the chiral soliton lattice, confined within an Abrikosov-Nielsen-Olesen (ANO) vortex of the charged pions. This structure undergoes a drastic transformation when the pion mass is introduced, i.e., both charged and neutral pions condense in the bulk, allowing two distinct types of vortices: the charged pions constitute a local ANO-like vortex, while the neutral pion configures a global vortex which is further attached to a domain wall also known as the chiral soliton. Remarkably, the ANO vortex forms a topological linking with the closed global vortex line, when $\mu_B$ exceeds its critical value as a function of $\mu_I$. The linking number has the physical meaning of the baryon number in view of the Wess-Zumino-Witten term. In this sense, the linked configuration realizes a stable Skyrmion-type solution, but innovatively without the Skyrme term. We therefore propose a novel phase of dense baryonic matter comprised of such vortices, which shall play a role in the low-energy QCD phase diagram.",2025,"['Yu Hamada', 'Muneto Nitta', 'Zebin Qiu']",http://arxiv.org/abs/2509.20844v1,arxiv,,,,,,,2509.20844v1,,False
,,"Relevant Deformations, Brane Brick Models and Triality","We extend the study of relevant deformations connecting 2d (0,2) gauge theories on D1-branes probing toric Calabi-Yau 4-folds beyond pure mass deformations. The underlying geometry provides powerful insights when field-theoretic tools are still lacking. We observe that the volume of the Sasaki-Einstein base of the Calabi-Yau 4-fold grows towards the IR, signaling the relevance of deformations. We exploit the map between gauge theory fields and GLSM fields to compute scaling dimensions directly from divisor volumes, allowing for a sharper determination of whether terms in the Lagrangian are relevant or irrelevant. Moreover, this map provides a systematic way to determine the precise set of terms needed to realize a given deformation. We also explore the interplay between general relevant deformations and triality, studying cases where non-mass deformations are mapped to mass deformations in a dual theory, and resolving puzzles that seem to require non-holomorphic couplings in one of the dual phases. Finally, we present evidence that when the Hilbert series of the mesonic moduli space is refined only under the U(1) R-symmetry, it becomes invariant even under non-mass relevant deformations of the brane brick models corresponding to toric Calabi-Yau 4-folds related by a birational transformation, extending previous results to a broader class of deformations.",2025,"['Mario Carcamo', 'Sebastian Franco', 'Dongwook Ghim', 'Georgios P. Goulas', 'Rak-Kyeong Seong']",http://arxiv.org/abs/2510.05517v1,arxiv,,,,,,,2510.05517v1,,False
,,Heterogeneous Point Set Transformers for Segmentation of Multiple View   Particle Detectors,"NOvA is a long-baseline neutrino oscillation experiment that detects neutrino particles from the NuMI beam at Fermilab. Before data from this experiment can be used in analyses, raw hits in the detector must be matched to their source particles, and the type of each particle must be identified. This task has commonly been done using a mix of traditional clustering approaches and convolutional neural networks (CNNs). Due to the construction of the detector, the data is presented as two sparse 2D images: an XZ and a YZ view of the detector, rather than a 3D representation. We propose a point set neural network that operates on the sparse matrices with an operation that mixes information from both views. Our model uses less than 10% of the memory required using previous methods while achieving a 96.8% AUC score, a higher score than obtained when both views are processed independently (85.4%).",2025,"['Edgar E. Robles', 'Dikshant Sagar', 'Alejandro Yankelevich', 'Jianming Bian', 'Pierre Baldi', 'NOvA Collaboration']",http://arxiv.org/abs/2510.09659v1,arxiv,,,,,,,2510.09659v1,,True
,,Machine learning approach to QCD kinetic theory,"The effective kinetic theory (EKT) of QCD provides a possible picture of various non-equilibrium processes in heavy- and light-ion collisions. While there have been substantial advances in simulating the EKT in simple systems with enhanced symmetry, eventually, event-by-event simulations will be required for a comprehensive phenomenological modeling. As of now, these simulations are prohibitively expensive due to the numerical complexity of the Monte Carlo evaluation of the collision kernels. In this talk, we show how the evaluation of the collision kernels can be performed using neural networks paving the way to full event-by-event simulations.",2025,"['Sergio Barrera Cabodevila', 'Aleksi Kurkela', 'Florian Lindenbauer']",http://arxiv.org/abs/2509.26374v1,arxiv,,,,,,,2509.26374v1,,True
,,TrackFormers Part 2: Enhanced Transformer-Based Models for High-Energy   Physics Track Reconstruction,"High-Energy Physics experiments are rapidly escalating in generated data volume, a trend that will intensify with the upcoming High-Luminosity LHC upgrade. This surge in data necessitates critical revisions across the data processing pipeline, with particle track reconstruction being a prime candidate for improvement. In our previous work, we introduced ""TrackFormers"", a collection of Transformer-based one-shot encoder-only models that effectively associate hits with expected tracks. In this study, we extend our earlier efforts by incorporating loss functions that account for inter-hit correlations, conducting detailed investigations into (various) Transformer attention mechanisms, and a study on the reconstruction of higher-level objects. Furthermore we discuss new datasets that allow the training on hit level for a range of physics processes. These developments collectively aim to boost both the accuracy, and potentially the efficiency of our tracking models, offering a robust solution to meet the demands of next-generation high-energy physics experiments.",2025,"['Sascha Caron', 'Nadezhda Dobreva', 'Maarten Kimpel', 'Uraz Odyurt', 'Slav Pshenov', 'Roberto Ruiz de Austri Bazan', 'Eugene Shalugin', 'Zef Wolffs', 'Yue Zhao']",http://arxiv.org/abs/2509.26411v1,arxiv,,,,,,,2509.26411v1,,True
,,"Quantum Simulation of Fermions in $AdS_2$ Black Hole: Chirality,   Entanglement, and Spectral Crossovers","We consider free Dirac fermions on a discretized $AdS_2$ black hole background, and analyze how curved space redshift, horizons, and the spin connection induced chiral gravitational effect shape spectral, transport, and scrambling phenomena. The system is discretized via staggered fermions followed by the Jordan-Wigner transform to encode the model in qubit degrees of freedom, whose Hamiltonian carries site dependent warp factors and bond chirality terms encoding the redshift and spin connection effects. We calculate the ground state and first excited states energies, their local charge profiles, and their half-chain entanglement entropies, showing how redshift and chirality affect the transition from criticality to a gapped regime. Probing operator growth via out-of-time-order correlators, we find that horizons and the chiral coupling accelerate scrambling, yet remain within a non-chaotic regime. Finally, we map out an integrable to ergodic crossover via level-spacing statistics and Brody fits, and introduce on-site disorder to drive a many body localization transition.",2025,"['Kazuki Ikeda', 'Yaron Oz']",http://arxiv.org/abs/2509.21410v1,arxiv,,,,,,,2509.21410v1,,False
,,"Curvature-Aware Deep Learning for Vector Boson Fusion: Differential   Geometry, Physics-Inspired Features, and Quantum Method Limitations","Particle physics classification often assumes flat geometry, ignoring the curved statistical structure of collision data. We present a geometric framework for Vector Boson Fusion Higgs classification that combines physics-inspired observables with product manifold neural networks. The method unifies Euclidean, hyperbolic, and spherical representations to capture nonlinear correlations among kinematic features. Geometric embedding yields measurable improvements over flat baselines, demonstrating that curvature-aware architectures recover information lost in standard approaches. The study highlights how incorporating geometric structure enhances discrimination power in high-energy collision data.",2025,['Alibordi Muhammad'],http://arxiv.org/abs/2510.04887v1,arxiv,,,,,,,2510.04887v1,,True
